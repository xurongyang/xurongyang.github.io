<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[zab&raft&paxos]]></title>
    <url>%2F2019%2F09%2F22%2Fzab-raft-paxos%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[知识储备总结]]></title>
    <url>%2F2019%2F09%2F13%2F%E7%9F%A5%E8%AF%86%E5%82%A8%E5%A4%87%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[命令备忘]]></title>
    <url>%2F2019%2F06%2F11%2F%E5%91%BD%E4%BB%A4%E5%A4%87%E5%BF%98%2F</url>
    <content type="text"><![CDATA[1sed -e &apos;s/ /\&apos;$&apos;\n/g&apos; file (For mac)]]></content>
  </entry>
  <entry>
    <title><![CDATA[etcd解读]]></title>
    <url>%2F2019%2F04%2F24%2Fetcd%E8%A7%A3%E8%AF%BB%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[系统设计原则]]></title>
    <url>%2F2019%2F04%2F06%2F%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99%2F</url>
    <content type="text"><![CDATA[隔离哪些变更原因不同的部分，集成变更原因相同的部分 一个系统可以被解耦成若干个水平分层-UI界面，应用独有的业务逻辑，领域普适的业务逻辑，数据库]]></content>
  </entry>
  <entry>
    <title><![CDATA[Go总结]]></title>
    <url>%2F2019%2F01%2F28%2FGo%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[优点：1.生成直接可执行的二进制文件2.gofmt3.内置的channel（消息队列）4.构造函数很灵活5.加强版for循环 缺点：1.莫名其妙的类型系统（interface vs Java的Object基类和interface）2.奇怪的数组定义（[5]string）3.自动绑定接口实现（不知道实现了哪个接口）4.错误处理和泛型（已被大家所熟知）]]></content>
  </entry>
  <entry>
    <title><![CDATA[JVM堆外内存]]></title>
    <url>%2F2018%2F12%2F25%2FJVM%E5%A0%86%E5%A4%96%E5%86%85%E5%AD%98%2F</url>
    <content type="text"><![CDATA[堆外内存分布情况]]></content>
  </entry>
  <entry>
    <title><![CDATA[DDIA笔记]]></title>
    <url>%2F2018%2F03%2F25%2FDDIA%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[第一章 可靠性、可扩展性、可维护性什么是可靠性，可扩展性和可维护性？ 可靠性：硬件故障，软件故障，人为操作故障 可扩展性：描述负载，描述性能，应对负载的方法 可维护性：自动化运维，降低系统复杂度，拥抱变化（轻松应对变化） 第二章 数据模型与查询语言每个层都通过提供一个明确的数据模型来隐藏更低层次中的复杂性。这些抽象允许不同的人群有效地协作（例如数据库厂商的工程师和使用数据库的应用程序开发人员）。 掌握一个数据模型需要花费很多精力（想想关系数据建模有多少本书）。即便只使用一个数据模型，不用操心其内部工作机制，构建软件也是非常困难的。然而，因为数据模型对上层软件的功能（能做什么，不能做什么）有着至深的影响，所以选择一个适合的数据模型是非常重要的。 比较关系模型：关系型模型相对于文档模型的优点在于支持多对一和多对多的关系。 第三章BitcaskBitcask索引是保存在内存中的哈希表，非常适合每个key都经常更新的情况。因为只需一次磁盘寻道就可以从磁盘加载这些值。 如果数据文件的那部分已经在文件系统缓存中，则读取根本不需要任何磁盘I / O。 Bitcask通过在磁盘上存储每个分段的哈希映射的快照来加速恢复索引，使得索引可以更快地加载到内存中。 数据库可能随时崩溃，包括在记录附加记录的一半。 Bitcask文件包含校验和，允许检测并忽略这些损坏的日志部分。 由于写操作是以严格顺序的顺序附加到日志中的，所以常见的实现选择是只有一个写入线程。 数据文件段只能新增，所以它们可以由多个线程同时读取。]]></content>
      <categories>
        <category>分布式</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Synchronized实现]]></title>
    <url>%2F2017%2F09%2F01%2FSynchronized%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[synchronized用法synchronized是Java语言中用于线程间并发互斥访问的关键字，通常有两种用法。 synchronized修饰对象123456789public void method() &#123; synchronized (someObject) &#123; // code &#125; // no effect synchronized (new Object()) &#123; &#125;&#125; 当synchronized修饰的是对象时，实际上对synchronized块的代码加了一个对象锁，只有获取到这个锁才能执行synchronized块的代码，达到了互斥访问的效果。 倘若synchronized修饰的是new Object()呢？因为每次执行到此处时都会对这个新创建出来的对象加锁，而每次加锁的对象又都不相同，所以没有办法达到互斥访问的目的。 synchronized修饰方法123public synchronized method1() &#123;&#125;public static synchronized method2() &#123;&#125; synchronized修饰方法需要区分修饰的是实例方法还是类方法，倘若修饰的是实例方法的话，那么synchronized加锁的对象就是对应的类实例，倘若修饰的是类方法的话，那么synchronized加锁的对象就是该类的Class对象。 synchronized的字节码表示synchronized作为一个关键字在代码层面就是这样了，下面我们分析下它在字节码层面的表示。先看一段代码： 1234567891011public class SyncCodeBlock &#123; public int i; public void syncTask()&#123; //同步代码库 synchronized (this)&#123; i++; &#125; &#125;&#125; 通过javap反编译，得到的字节码如下： 123456789101112131415161718192021222324252627282930313233343536Compiled from "SyncCodeBlock.java"public class SyncCodeBlock &#123; public int i; public SyncCodeBlock(); Code: 0: aload_0 1: invokespecial #1 // Method java/lang/Object."&lt;init&gt;":()V 4: return public void syncTask(); Code: 0: aload_0 1: dup 2: astore_1 3: monitorenter 4: aload_0 5: dup 6: getfield #2 // Field i:I 9: iconst_1 10: iadd 11: putfield #2 // Field i:I 14: aload_1 15: monitorexit 16: goto 24 19: astore_2 20: aload_1 21: monitorexit 22: aload_2 23: athrow 24: return Exception table: from to target type 4 16 19 any 19 22 19 any&#125; 对上面的代码做个简化，去掉与synchronized没关系的逻辑，简化版如下 ： 1234563: monitorenter //进入同步方法//..........省略其他 15: monitorexit //退出同步方法16: goto 24//省略其他.......21: monitorexit //退出同步方法 当执行monitorenter指令时，会尝试获取对象的锁，如果该对象锁在执行前没有被锁定或者当前线程已经拥有了该对象的锁，就把锁的计数器加一。相应的，在执行monitorexit指令时会将锁计数器减一，当锁计数器值为0时，锁就被释放。如果获取锁失败，该线程就要阻塞等待，知道对象锁被另外一个线程释放。 值得注意的是编译器将会确保无论方法通过何种方式完成，方法中调用过的每条 monitorenter 指令都有执行其对应 monitorexit 指令，而无论这个方法是正常结束还是异常结束。为了保证在方法异常完成时 monitorenter 和 monitorexit 指令依然可以正确配对执行，编译器会自动产生一个异常处理器，这个异常处理器声明可处理所有的异常，它的目的就是用来执行 monitorexit 指令。从字节码中也可以看出多了一个monitorexit指令，它就是异常结束时被执行的释放monitor 的指令。 对于synchronized修饰的是方法的情况，在反编译的字节码中并没有monitorenter和monitorexit指令，字节码中的方法申明和代码中保持一致，例如： 1234567public static synchronized void syncTask(); Code: 0: getstatic #2 // Field i:I 3: iconst_1 4: iadd 5: putstatic #2 // Field i:I 8: return 其实无论字节码中是monitorenter也好，还是monitorexit也好，都只是告知虚拟机进行锁操作的标志。 synchronized锁优化对象头在 HotSpot 虚拟机中，对象在内存中存储布局分为 3 块区域：对象头（Header）、实例数据（Instance Data）、对齐填充。 HotSpot 虚拟机的对象头包括两部分（非数组对象）信息，如下图所示： 第一部分用于存储对象自身的运行时数据，如哈希码（HashCode）、GC 分代年龄、锁状态标志、线程持有的锁、偏向线程 ID、偏向时间戳、对象分代年龄，这部分信息称为“Mark Word”；Mark Word 被设计成一个非固定的数据结构以便在极小的空间内存储尽量多的信息，它会根据自己的状态复用自己的存储空间。 第二部分是类型指针，即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例； 如果对象是一个 Java 数组，那在对象头中还必须有一块用于记录数组长度的数据。因为虚拟机可以通过普通 Java 对象的元数据信息确定 Java 对象的大小，但是从数组的元数据中无法确定数组的大小。 这部分数据的长度在 32 位和 64 位的虚拟机（未开启压缩指针）中分别为 32bit 和 64bit。 在 32 位系统下，存放 Class 指针的空间大小是 4 字节，Mark Word 空间大小也是4字节，因此头部就是 8 字节，如果是数组就需要再加 4 字节表示数组的长度，如下表所示： 实例数据实例数据部分是对象真正存储的有效信息，也是在程序代码中所定义的各种类型的字段内容。 这部分的存储顺序会受到虚拟机分配策略参数（FieldsAllocationStyle）和字段在 Java 源码中定义顺序的影响。 对齐填充对齐填充不是必然存在的，没有特别的含义，它仅起到占位符的作用。 由于 HotSpot VM 的自动内存管理系统要求对象起始地址必须是 8 字节的整数倍，也就是说对象的大小必须是 8 字节的整数倍。对象头部分是 8 字节的倍数，所以当对象实例数据部分没有对齐时，就需要通过对齐填充来补全。 偏向锁偏向锁是Java 6之后加入的新锁，它是一种针对加锁操作的优化手段，经过研究发现，在大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得，因此为了减少同一线程获取锁(会涉及到一些CAS操作,耗时)的代价而引入偏向锁。偏向锁的核心思想是，如果一个线程获得了锁，那么锁就进入偏向模式，此时Mark Word 的结构也变为偏向锁结构，当这个线程再次请求锁时，无需再做任何同步操作，即获取锁的过程，这样就省去了大量有关锁申请的操作，从而也就提供程序的性能。所以，对于没有锁竞争的场合，偏向锁有很好的优化效果，毕竟极有可能连续多次是同一个线程申请相同的锁。但是对于锁竞争比较激烈的场合，偏向锁就失效了，因为这样场合极有可能每次申请锁的线程都是不相同的，因此这种场合下不应该使用偏向锁，否则会得不偿失，需要注意的是，偏向锁失败后，并不会立即膨胀为重量级锁，而是先升级为轻量级锁。下面我们接着了解轻量级锁。 轻量级锁倘若偏向锁失败，虚拟机并不会立即升级为重量级锁，它还会尝试使用一种称为轻量级锁的优化手段(1.6之后加入的)，此时Mark Word 的结构也变为轻量级锁的结构。轻量级锁能够提升程序性能的依据是“对绝大部分的锁，在整个同步周期内都不存在竞争”，注意这是经验数据。需要了解的是，轻量级锁所适应的场景是线程交替执行同步块的场合，如果存在同一时间访问同一锁的场合，就会导致轻量级锁膨胀为重量级锁。 自旋锁轻量级锁失败后，虚拟机为了避免线程真实地在操作系统层面挂起，还会进行一项称为自旋锁的优化手段。这是基于在大多数情况下，线程持有锁的时间都不会太长，如果直接挂起操作系统层面的线程可能会得不偿失，毕竟操作系统实现线程之间的切换时需要从用户态转换到核心态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高，因此自旋锁会假设在不久将来，当前的线程可以获得锁，因此虚拟机会让当前想要获取锁的线程做几个空循环(这也是称为自旋的原因)，一般不会太久，可能是50个循环或100循环，在经过若干次循环后，如果得到锁，就顺利进入临界区。如果还不能获得锁，那就会将线程在操作系统层面挂起，这就是自旋锁的优化方式，这种方式确实也是可以提升效率的。最后没办法也就只能升级为重量级锁了。 参考 http://www.cnblogs.com/zhengbin/p/6490953.html http://blog.csdn.net/javazejian/article/details/72828483]]></content>
      <categories>
        <category>并发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[爬虫系统设计]]></title>
    <url>%2F2017%2F05%2F31%2F%E7%88%AC%E8%99%AB%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[爬虫框架 &amp; 爬虫系统爬虫框架和爬虫系统有什么区别？其实就类似于Spring框架和借助Spring完成功能开发的Java工程两者之间的关系。 框架的目标在于解决某些特定的通用的技术问题，比如Spring框架解决了对象之间的依赖关系，Mybatis框架解决了数据库数据与domain对象的转换等。在做Java web开发中，每个Java系统都会面临这样的技术问题，于是有人就开发了解决这些问题的通用框架，利用这些框架能极大得提升开发效率。 系统的目标是解决业务问题。比如电商系统要解决用户浏览，加入购物车，下单等操作。它的核心点就是业务，技术在其次。 可以说，系统是建立在框架之上的，利用好技术框架就能更快解决技术问题，加速业务开发进度。 爬虫框架和爬虫系统的关系也是这样的，只不过不同于常规的业务系统和技术框架，爬虫系统也更偏向于技术，而不是业务。 爬虫系统的关键点 统一实体定义。每一个被抓取的数据称之为一个实体，比如一个豆瓣的图书，一个时光网的电影。我们通过实体来源，实体类型，实体唯一ID来精确描述一个被抓取的数据。统一实体定义是爬虫系统的基石，没有统一实体定义就无法建立一个面向任何类型数据的爬虫系统。 任务调度。一个成熟的爬虫系统断然不会只跑一个抓取任务，我们面临的问题是多爬虫任务同时在多台机器上运行，分布式任务调度系统是个必然选项。 数据存储。数据存储要解决两个问题，一个是要存什么数据，二是怎么存。目前我们会存储原始抓取数据和解析后数据。存储原始抓取数据目的是发现解析过程有问题时可以调试，当修复完解析逻辑后还能够进行重新清洗。存储解析后数据主要是保存抓取到的有价值的数据以备他用。怎么存？原始数据我们用了MySQL分区表，利用主键id分区，会定期删掉老数据。解析后数据存放在ElasticSearch中，便于查询检索。 匹配算法。当我们把数据抓取到并且解析成结构化数据存放在ES中后，整个流程并不是就终止了，我们还需要把这些外来数据补充到我们原有的数据中去。举个例子，我们抓取了豆瓣的《大话西游》电影条目，为了把豆瓣的数据补充到我们的库中，我们需要计算出我们库中已有的《大话西游》电影实际上和豆瓣的是一样的数据。我们利用匹配算法达成这一目标。 爬虫系统架构图 爬虫系统设计思路我们把爬虫各个环节做了梳理之后，按照单一职责原则，划分出抓取服务，清洗服务，推送服务，匹配服务这四个服务。 抓取服务。负责抓取和简单解析数据，抓取任务通过分布式任务框架调度。 清洗服务。负责数据清洗和归一化，处理完成的数据会写入到ES中存储。 推送服务。负责接收清洗服务清洗完成的数据，并且根据不同业务方的需要进行对象转换，然后推送到业务方。 匹配服务。负责计算外源数据与已有数据的相似度，产出匹配关系]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JSR 133 FAQ翻译]]></title>
    <url>%2F2017%2F05%2F20%2FJSR-133-FAQ%E7%BF%BB%E8%AF%91%2F</url>
    <content type="text"><![CDATA[原文地址：https://www.cs.umd.edu/~pugh/java/memoryModel/jsr-133-faq.html 内存模型到底是什么在多处理器计算机系统中，处理器一般拥有多层次的内存缓存，内存缓存一方面能够提高访问数据的速度（因为数据离处理器更近了），另一方面能降低总线的流量（因为许多内存操作可以被缓存替代）。内存缓存能极大的提高性能，但是也带来了一些挑战。例如，当两个处理器同时访问同一个内存地址时会发生什么事情？在什么情况下他们能看到相同的值？ 在处理器级别，存储器模型定义了必要和充分的条件，用于知道其他处理器对存储器的写入对于当前处理器是可见的，并且当前处理器的写入对于其他处理器是可见的。一些处理器应用了强一致内存模型，所有的处理器对于同一个内存地址，看到的值都是一样的。其它一些处理器应用了弱一些的内存模型，利用内存屏障来刷新处理器本地缓存，这样处理器就能看到其它处理器的写操作的结果。这些内存屏障通常在lock和unlock操作时执行，它们对于高级程序设计语言是透明的。 在强一致内存模型下编写程序通常更为容易，因为不需要用到内存屏障。然而，即使是一致性最强的内存模型也经常会用到内存屏障。往往他们的位置都是违反直觉的。处理器设计的最新趋势鼓励了较弱的内存模型，因为它们对缓存一致性的放宽使得可以在多个处理器和更大量的内存中实现更大的可扩展性。 一个写入操作什么时间对另外一个线程可见的问题部分是由编译器重排序导致的。例如，编译器可能会决定把一个写入操作推迟执行会更加高效。只有不改变程序的语义即可。如果编译器推迟了一个操作，另一个线程直到它真正执行后才会看到操作结果，这反应了缓存的效果（最后半句有点奇怪）。 此外，写操作也可能会提前，在这种情况下，其它线程可能会提前看到一个写操作发生。所有这些都是特意设计的 - 通过给编译器，运行时或硬件提供灵活性，以最佳顺序在内存模型的范围内执行操作，我们可以实现更高的性能。 举一个简单的例子： 123456789101112Class Reordering &#123; int x = 0, y = 0; public void writer() &#123; x = 1; y = 2; &#125; public void reader() &#123; int r1 = y; int r2 = x; &#125;&#125; 假设这段代码被两个线程并发执行，并且y读取到的值是2。因为y的写入在x之后，所以程序员可能会认为x的值必定是1。然而，写操作可能被重排序了，如果发生这种情况，可能会先写入y，然后发生两个变量的读取，最后写入x。 结果是r1的值为2，但r2的值为0。 Java内存模型描述了多线程代码中的哪些行为是合法的，以及线程如何通过内存进行交互。 它描述了程序中变量之间的关系以及在实际计算机系统中存储和检索内存或寄存器的底层细节。 它可以使用各种各样的硬件和各种编译器优化来正确实现。 Java包括几种语言结构，包括volatile，final和synchronized，它们旨在帮助程序员将程序的并发要求提供给编译器。 Java内存模型定义了volatile和synchronized的行为，更重要的是确保正确同步的Java程序在所有处理器架构上正确运行。 其它语言有没有内存模型大多数其他编程语言（如C和C ++）并没有直接支持多线程。 这些语言抑制编译器和体系结构中的重排序提供给程序员的保护在很大程度上取决于所使用的线程库（例如pthreads），使用的编译器以及运行代码的平台提供的保证。 JSR 133讲了什么内容自1997年以来，在Java语言规范第17章定义的Java Memory Model中发现了几个严重的缺陷。 这些缺陷允许混淆行为（例如观察到final改变了其值），并且破坏了编译器执行常见优化的能力。 Java内存模型是一项雄心勃勃的工作; 这是第一次编程语言规范试图并入一个内存模型，可以为各种架构的并发提供一致的语义。 不幸的是，定义一个一致和直观的记忆模型比预期的困难得多。 JSR 133定义了一种用于Java语言的新内存模型，它修复了较早内存模型的缺陷。 为了做到这一点，final和volatile的语义需要改变。 完整内容可以在http://www.cs.umd.edu/users/pugh/java/memoryModel找到，but the formal semantics are not for the timid（这句不懂）.It is surprising, and sobering, to discover how complicated seemingly simple concepts like synchronization really are（这句也是）.幸运的是，你不需要了解正式语义的细节 - JSR 133的目标是创建一套语义，为volatile，synchronized和final提供了一个直观的框架。 JSR 133的目标包括： 保持现有的安全保障，如类型安全，加强其他。 例如，变量值可能不会被创建为某个没有赋值给它的值：由某个线程观察到的变量的每个值必须是由某个线程设置过的值。 正确同步程序的语义应尽可能简单直观。 应该定义不完整或不正确同步的程序的语义，以使潜在的安全隐患最小化。（不懂） 程序员应该能够自信地说明多线程程序如何与内存交互。 应该可以在广泛的流行硬件架构中设计正确的，高性能的JVM实现。 应提供初始化安全的新保证。 如果对象被正确构造（这意味着在构造过程中它的引用不会逸出），那么可以看到对该对象的引用的所有线程也将看到在构造函数中设置的final域的值，而不需要同步。 对已存在的代码有很小的影响 重排序的含义是什么？有许多情况下，程序变量（对象实例字段，类静态字段和数组元素）的访问可能会以与程序指定的不同的顺序执行。 编译器可以按照优化的名义，对指令进行重排序。 数据可以在寄存器，处理器高速缓存和主存储器之间以与程序指定的顺序不同的顺序移动。 例如，如果线程先写入字段a，然后写入字段b，并且b的值不依赖于a的值，则编译器可以自由地对这些操作进行重新排序，并且缓存可以自由地刷新b的值到内存，在a之前。 有一些潜在的重新排序来源，如编译器，JIT和缓存。 编译器，运行时和硬件会创造一个as-if-serial语义的错觉，这意味着在一个单线程程序中，该程序不应该能够观察到重排序的影响。 然而，重排序可能会在不正确同步的多线程程序中发挥作用，其中一个线程能够观察到其他线程的影响，并且可能能够检测到该变量访问以与代码顺序不同的方式显示给其他线程。 大多数时候，一个线程不在乎其它线程在做什么。 但是，如果它在乎，就需要用到同步。 旧内存模型有什么问题？旧的内存模型有几个严重的问题。它很难理解，因此被广泛的违背。例如，旧的内存模型在很多情况下都没有允许在大多数JVM中应用的重排序措施。这带来了JSR 133的形成。 例如，一个广泛认同的观点是，如果使用final，则线程之间的同步是不必要的，以保证另一个线程将看到该字段的值。 虽然这是一个合理的假设和一个明智的行为，实际上我们想要的东西如何工作，在旧的记忆模式下，根本不是这么做的。 旧的内存模型中没有任何内容表明它处理final字段与任何其他字段不同 - 意思是同步是确保所有线程都看到由构造函数编写的最终字段的值的唯一方法。 因此，线程可能会看到该字段的默认值，然后在稍后的时间内看到其构造的值。 这意味着，例如，像String这样的不可变对象似乎可以改变它们的值 - 这是一个令人不安的现象。 旧的内存模型允许volatile与非volatile的读写操作进行重排序，这与大多数开发人员对volatile的直觉不一致，从而导致混乱。 最后，正如我们将看到的那样，程序员对程序错误同步时可能会发生什么的直觉通常是错误的。 JSR-133的目标之一是提请注意到这一事实。 “非正确同步”是什么意思？不正确同步的代码对于不同人的含义不一样。 当我们谈到在Java内存模型的上下文中错误地同步的代码时，我们的意思是任何代码 有一个线程写入一个变量 有另一个线程读取相同的变量 写入和读取没有用同步操作来排序 当这些规则被违反时，我们说我们在这个变量上有一个数据竞争。 具有数据竞争的程序是一个不正确同步的程序。 Synchronization同步操作做了什么同步有几个方面。 最容易理解的是互斥 - 只有一个线程可以拿到一个监视器锁，因此在监视器锁上同步意味着一旦一个线程进入被监视器锁保护的同步块，则没有其他线程可以进入该监视器锁保护的块，直到第一个线程退出同步块。 但是不仅仅是互斥访问，Synchronization同步确保在同步块之前或期间，线程的内存写入以可预测的方式显示给同一监视器上同步的其他线程。 在我们退出同步程序段后，我们释放监视器锁，该监视器锁具有将缓存刷新到内存的作用，使得此线程所做的写入对其他线程可见。 在我们可以进入同步块之前，我们需要获取监视器锁，该监视器锁具有使本地处理器缓存无效的效果，以便从内存重新加载变量。 然后，我们将能够看到所有的上一版本都可以看到的写入。 在缓存方面进行讨论，可能听起来好像这些问题只影响多处理器机器。 然而，可以在单个处理器上轻松看到重新排序的效果。 例如，编译器不会将acquire之后的代码移动到它之前，也不会把release之前的代码移动到它之后。当我们说acquire和release对缓存的操作时，我们忽略了很多的细节内容。 新的内存模型语义在内存操作（读取字段，写入字段，加锁，解锁）和其他线程操作（启动和连接）上创建了一些偏序规则，其中一些操作在其他操作之前发生。 当一个动作发生在另一个动作之前，第一个被保证在第二个之前被执行并且结果对其可见。 此排序的规则如下： 单线程中是完全按照代码顺序执行的 监视器的解锁操作发生在该监视器随后的加锁操作之前 对volatile字段的写入发生在该volatile字段每次后续读取之前 线程的start操作发生于该线程内的任何一行代码之前 一个线程内的所有操作都发生在join了这个线程的线程之前 这意味着一个线程在退出同步块之前的所有内存操作对于任何其它进入该同步块的线程都是可见的，因为所有的内存操作都发生在release之前，release发生在acquire之前。 另外一个含义是，下面的这个被许多人用作内存屏障的操作不起作用：1synchronized (new Object()) &#123;&#125; 这实际上没有任何效果，你的编译器可以完全删除它，因为编译器知道没有其他线程将在同一个监视器上同步。如果一个线程想看到另外一个线程的结果，就必须设置一个happens before规则。 重要提示：两个线程必须在同一个监视器锁上进行同步，这样才能设置happens before规则。如果线程A在X上同步，线程B在Y上同步，这样是没有效果的。release和acquire必须匹配，否则会存在数据竞争的问题。 不可见变量如何看起来修改了它的值最好的例子是String类的一个实现。 字符串可以实现为具有三个字段的对象 - 字符数组，该数组中的偏移量和长度。 以这种方式实现String的理由，而不是仅使用字符数组，它允许多个String和StringBuffer对象共享相同的字符数组，并避免额外的对象分配和复制。 所以，例如，String.substring（）方法可以通过创建一个新的字符串来实现，该字符串与原始的String共享相同的字符数组，并且在长度和偏移量字段中只是不同。 对于字符串，这些字段都是final字段。 12String s1 = "/usr/tmp";String s2 = s1.substring(4); 字符串s2的偏移量为4，长度为4.但是，在旧内存模型下，另一个线程可以将偏移量看作默认值为0，然后看到正确的值为4， 它将显示为字符串“/usr”更改为“/tmp”。 旧内存模型允许这种行为，几个JVM禁止了这些行为，在新的内存模型下，这种行为是违法的。 新的内存模型下final域的工作原理是怎样的？对象的final字段的值在其构造函数中设置。假设对象被正确构造，一旦构造完成，在构造函数中分配的final字段的值将对所有其他线程都是可见的，不需要同步。 此外，final字段引用的任何其他对象或数组的值将与final字段保持同步更新。 对象被正确构造是什么意思？ 这仅仅意味着在构造过程中，不允许正在构造的对象的引用“逃脱”。 （参见安全构造技术的例子）换句话说，不要对正在构造的对象引用另外一个线程可能看到的对象; 不要将其分配给静态字段，不要将其注册为与任何其他对象的监听器，等等。 这些任务应该在构造函数完成之后完成，而不是在构造函数中完成。 1234567891011121314151617181920class FinalFieldExample &#123; final int x; int y; static FinalFieldExample f; public FinalFieldExample() &#123; x = 3; y = 4; &#125; static void writer() &#123; f = new FinalFieldExample(); &#125; static void reader() &#123; if (f != null) &#123; int i = f.x; int j = f.y; &#125; &#125;&#125; 上面的类是一个使用final字段的例子。 线程执行reader保证为f.x看到值3，因为它是final的。不能保证为y看到值4，因为它不是final的。 如果FinalFieldExample的构造函数如下所示： 123456public FinalFieldExample() &#123; // bad! x = 3; y = 4; // bad construction - allowing this to escape global.obj = this;&#125; 那么从global.obj读取this的线程不能保证为x看到3。 能看到正确构造的字段值的能力是很好的，但是如果字段本身是引用，那么你还希望你的代码可以看到它指向的对象（或数组）的最新值。 如果你的领域是一个final域，这也是保证的。 所以，你可以有一个final指向数组的指针，而不用担心其他线程看到数组的引用是正确的，但数组的内容不正确。Again, by “correct” here, we mean “up to date as of the end of the object’s constructor”, not “the latest value available”. 现在，说完所有这一切，如果在一个线程构造一个不可变对象（即只包含final字段的对象）之后，你想要确保所有其他线程都能看到正确的值，你通常还需要使用同步。 没有其他方法来确保，例如，第二个线程将会看到对不可变对象的引用。程序从final字段获得的保证应该非常小心，深入细心地了解如何在代码中管理并发性。 用JNI修改final字段的值，这样的行为没有具体定义。 volatile做了什么volatile字段是用于在线程之间通信状态的特殊字段。每个读取的volatile的线程都会看到最后写入volatile的值; 实际上，它们被程序员设计为不会因为缓存或者重排序看不到最新的值的字段。禁止编译器和运行时环境在寄存器中分配volatile变量。 他们还必须确保在写入之后，将它们从缓存中刷新到内存，以便它们可以立即变得对其他线程可见。 类似地，在读取volatile字段之前，缓存必须被设置为无效，使得内存（而不是本地处理器高速缓存）中的值是最新的值。对volatile变量的访问重新排序也有其他限制。 在旧的内存模型下，volatile变量之间是不可以重排序的，但是和普通变量之间是可以重排序的，这破坏了volatile对于线程间传递信号的有用性。 在新的内存模型下，volatile变量之间还是不可以重排序，但是和普通变量之间也不可以重排序了。写入volatile的值和释放synchronized锁的内存效果是一样的，读取volatile的值和synchronized加锁的内存效果是一样的。实际上，因为新的存储器模型对于其他字段和volatile字段的重排序进行了更加严格的约束，无论是不是volatile变量，线程A在写入volatile字段f时可见的任何东西对于线程B在读取f时都是可见的。 下面是使用volatile的一个例子： 1234567891011121314class VolatileExample &#123; int x = 0; volatile boolean v = false; public void writer() &#123; x = 42; v = true; &#125; public void reader() &#123; if (v == true) &#123; //uses x - guaranteed to see 42. &#125; &#125;&#125; 假设一个线程正在调用writer，另一个线程是调用reader。 对v的写入器会把x的值写入到内存，并且v从内存中获取该值。 因此，如果读者看到v的值为true，那么也可以保证看到之前发生的写入42。 在旧的记忆模型下不是这样。 如果v不是volatile的，那么编译器可以对写入器中的写入进行重新排序，读者对x的读取可能会看到0。 volatile的语义被大大加强，几乎到达了synchronized的水平。对于可见性来说，volatile操作几乎和synchronized一样。 重要提示：和synchronized一样，必须用同一个volatile才能保证可见性。 新的内存模型是否修复了“双重锁定”问题？（臭名昭着的）双重检查锁定成语（也称为多线程单例模式）是一种技巧，旨在支持延迟初始化，同时避免同步的开销。在非常早期的JVM中，同步非常缓慢，开发人员急于删除它 - 也许太渴望了。双重锁定的模式如下所示： 12345678910111213// double-checked-locking - don't do this!private static Something instance = null;public Something getInstance() &#123; if (instance == null) &#123; synchronized (this) &#123; if (instance == null) instance = new Something(); &#125; &#125; return instance;&#125; 这看起来很聪明 - 在公共代码路径上避免了同步。 它只有一个问题 - 它没有作用。为什么没有作用？最明显的原因是初始化实例和对实例字段的写入可以由编译器或缓存重新排序，这将具有返回看起来是部分构造的对象的效果。 结果将是我们读取一个未初始化的对象。 还有很多其他原因能说明为什么这是错误的。没有办法使用旧的Java内存模型进行修复。更多信息可以查看：Double-checked locking: Clever, but broken和The “Double Checked Locking is broken” declaration 许多人认为使用volatile关键字会消除在尝试使用双重检查锁定模式时出现的问题。 在1.5之前的JVM中，volatile不会确保它有效。 在新的内存模型下，使实例字段volatile将“修复”双重锁定的问题，因为在构造和读取之间存在happens before关系。 用另外一种方式更好： 1234567private static class LazySomethingHolder &#123; public static Something something = new Something();&#125;public static Something getInstance() &#123; return LazySomethingHolder.something;&#125; 由于静态字段的初始化保证，该代码保证是正确的; 如果在静态初始化程序中设置了一个字段，那么它将被保证被正确地显示给访问该类的任何线程。 对虚拟机从业者你应该看 http://gee.cs.oswego.edu/dl/jmm/cookbook.html 为什么要关心内存模型？你为什么要关心？ 并发错误很难调试。他们经常不出现在测试中，需要等待，直到你的程序在高负载下运行，并且难以重现。 你最好提前花费额外的努力，以确保您的程序正确同步; 虽然这不容易，但比尝试调试严重同步的应用程序要容易得多。]]></content>
  </entry>
  <entry>
    <title><![CDATA[《Java并发编程实践》笔记3]]></title>
    <url>%2F2017%2F03%2F13%2F%E3%80%8AJava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B5%E3%80%8B%E7%AC%94%E8%AE%B03%2F</url>
    <content type="text"><![CDATA[Amdahl定律在增加计算资源的情况下，程序在理论上能够实现最高加速比，这个值取决于程序中可并行组件与串行组件所占的比重。假定F是必须串行执行的部分，在包含N个处理器的机器中，最高的加速比为： 线程的开销 上下文切换 内存同步 阻塞 降低锁的竞争程度 减少锁的持有时间 降低锁的请求频率 使用带有协调机制的独占锁，这些机制允许更高的并发性]]></content>
      <categories>
        <category>并发</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Java并发编程实践》笔记2]]></title>
    <url>%2F2017%2F03%2F12%2F%E3%80%8AJava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B5%E3%80%8B%E7%AC%94%E8%AE%B02%2F</url>
    <content type="text"><![CDATA[创建一个线程的开销到底有多大 Java栈 native栈 Executor框架Executor接口123public interface Executor &#123; void execute(Runnable command);&#125; 几个常见的线程池 newSingleThreadExecutor newFixedThreadPool newCachedThreadPool newScheduleredThreadPool ExecutorService接口扩展了Executor接口，添加了一些生命周期管理的方法 1234567public interface ExecutorService extends Executor &#123; void shutdown(); List&lt;Runnable&gt; shutdownNow(); boolean isShutdown(); boolean isTerminated(); boolean awaitTermination(long timeout, Timeunit unit) throws InterruptedException;&#125; ExecutorService的生命周期有三种状态： 运行 关闭 已终止 shutdown方法将执行平缓的关闭过程：不再接收新任务，同时等待已提交的任务执行完成（包括那些还未开始运行的）。 shutdownNow将执行粗暴的的关闭过程：尝试取消所有运行中的任务，并且不再启动队列中尚未开始执行的任务。 Callable和FutureExecutor执行的任务有4个生命周期：1.创建，2.提交，3.开始，4.完成。 Future表示一个任务的生命周期，提供了相应的方法来判断是否已经完成或者取消，以及获取任务的结果和取消任务等。 CompletionService12345678// 提交任务completionService.submit(new Callable())// 获取已完成的任务for (int t = 0; t &lt; tasks.size();i++) &#123; Future f = completionService.take(); Result r = f.get()&#125; invokeAll1List&lt;Future&gt; futures = executorService.invokeAll(tasks, time, unit); 取消与关闭interrupt调用interrupt并不会立即停止线程正在进行中的工作，只是传递了请求中断的消息。 通常，中断是实现取消最合理的方式 响应中断响应中断有两种方式：1.传递异常（interruptedException），2.恢复中断状态 超时取消 采用newTaskFor封装非标准的取消关闭ExecutorService12executorService.shutdown()executorService.awaitTermination(timeout, unit) 采用毒丸对象，读到该对象时就终止。 UncaughtExceptionHandler 关闭钩子 线程池使用最佳线程数对于计算密集型任务，在Ncpu的系统中，当线程池大小为Ncpu+1时通常能实现最佳的利用率（计算密集型线程会由于偶尔的页缺失中断或其他原因暂停时，这个线程可以补上）。 饱和策略 中止，默认策略，会抛出RejectExecutionException 调用者运行，主线程不会accept，到达的请求会保存在TCP队列中而不是应用程序的队列中。如果持续过载，TCP层将最终发现它的请求队列被填满，同样会开始抛弃请求。]]></content>
      <categories>
        <category>并发</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java锁是如何保证数据可见性的]]></title>
    <url>%2F2017%2F03%2F06%2FJava%E9%94%81%E6%98%AF%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%81%E6%80%A7%E7%9A%84%2F</url>
    <content type="text"><![CDATA[引言在 java.util.concurrent.locks.Lock 接口的Javadoc中有这样一段话： All Lock implementations must enforce the same memory synchronization semantics as provided by the built-in monitor lock : A successful lock operation acts like a successful monitorEnter action A successful unlock operation acts like a successful monitorExit action Unsuccessful locking and unlocking operations, and reentrant locking/unlocking operations, do not require any memory synchronization effects. 这段话的核心是j.u.c.locks.Lock接口的实现类具有和synchronized内置锁一样的内存同步语义。 不同于由JVM底层实现的内置锁，Lock接口的实现类是直接用Java代码实现的。如何保证了内存中数据的可见性？下面进行一下分析。 可见性什么是可见性？如果一个线程对于另外一个线程是可见的，那么这个线程的修改就能够被另一个线程立即感知到。用一个简单的例子来说明： 12345678910111213boolean ok = false;int a = 0;// Thread aa = 1ok = true// Thread b// 可能一直循环下去while (ok) &#123; // 输出的number的值不一定是1 System.out.println(a)&#125; Thread b中的循环可能会一直持续下去，因为Thread a设置的ok的值并不一定立即被Thread b感知到，并且输出的a的值也不一定是1。 在多线程程序中，没有做正确的同步是无法保证内存中数据的可见性的。 用锁来保证可见性我们可以利用Java锁来保证多线程程序中数据的可见性，来看下面这个例子： 12345678910111213141516171819202122232425public class Counter &#123; private static int counter = 0; // 第一种方式：没有做同步操作 public static int incrCounter1() &#123; return counter++; &#125; // 第二种方式：使用synchronized同步 public synchronized static int incrCounter2() &#123; return counter++; &#125; // 第三种方式：使用ReentrantLock同步 private static ReentrantLock lock = new ReentrantLock(); public static int incrCounter3() &#123; try &#123; lock.lock(); return counter++; &#125; finally &#123; lock.unlock(); &#125; &#125;&#125; 显然，incrCounter1不是线程安全的，在一个线程写入一个最新的值后，无法保证另外一个线程能立即读到最新写入的值，incrCounter2和incrCounter3分别利用内置锁synchronized和ReentrantLock来保证了其它线程能看到最新的counter的值，达到我们想要的效果。 Java锁保证可见性的具体实现Happens-before规则从JDK 5开始，JSR-133定义了新的内存模型，内存模型描述了多线程代码中的哪些行为是合法的，以及线程间如何通过内存进行交互。 新的内存模型语义在内存操作（读取字段，写入字段，加锁，解锁）和其他线程操作上创建了一些偏序规则，这些规则又叫作Happens-before规则。它的含义是当一个动作happens before另一个动作，这意味着第一个动作被保证在第二个动作之前被执行并且结果对其可见。我们利用Happens-before规则来解释Java锁到底如何保证了可见性。 Java内存模型一共定义了八条Happens-before规则，和Java锁相关的有以下两条： 内置锁的释放锁操作发生在该锁随后的加锁操作之前 一个volatile变量的写操作发生在这个volatile变量随后的读操作之前 synchronized提供的可见性synchronized有两种用法，一种可以用来修饰方法，另外一种可以用来修饰代码块。我们以synchronized代码块为例： 123synchronized(SomeObject) &#123; // code&#125; 因为synchronized代码块是互斥访问的，只有一个线程释放了锁，另一个线程才能进入代码块中执行。 由上述Happens-before规则第一条： 内置锁的释放锁操作发生在该锁随后的加锁操作之前 假设当线程a释放锁后，线程b拿到了锁并且开始执行代码块中的代码时，线程b必然能够看到线程a看到的所有结果，所以synchronized能够保证线程间数据的可见性。 j.u.c.locks.Lock提供的可见性volatile关键字的可见性对第一个代码样例做一下改造，用volatile关键字来修饰ok，其余不变： 123456789101112volatile boolean ok = falseint a = 0// Thread aa = 1ok = true// Thread bif (ok) &#123; // 确保a的值为1 System.out.println(a)&#125; 根据上述Happens-before规则第二条： 一个volatile变量的写操作发生在这个volatile变量随后的读操作之前 假设线程a将ok的值设置为true，那么如果线程b看到ok的值为true，一定可以保证输出的a的值是1。 ReentrantLock可见性保证的具体实现j.u.c.locks.Lock接口定义了六个方法： 12345678public interface Lock &#123; void lock(); void lockInterruptibly() throws InterruptedException; boolean tryLock(); boolean tryLock(long time, TimeUnit unit) throws InterruptedException; void unlock(); Condition newCondition();&#125; 在j.u.c包中实现Lock接口的类主要有ReentrantLock和ReentrantReadWriteLock，下面以ReentrantLock为例来说明（ReentrantReadWriteLock原理相同）。 先来看ReentrantLock类的lock方法和unlock方法的实现： 123456789101112public void lock() &#123; sync.lock();&#125;// sync.lock()实现final void lock() &#123; acquire(1);&#125;public void unlock() &#123; sync.release(1);&#125; lock方法和unlock方法的具体实现都代理给了sync对象，来看一下sync对象的定义： 1234567abstract static class Sync extends AbstractQueuedSynchronizerstatic final class FairSync extends Syncpublic ReentrantLock(boolean fair) &#123; sync = fair ? new FairSync() : new NonfairSync();&#125; 根据ReentrantLock的构造参数，sync对象可以是FairSync（公平锁）或者是NonfairSync（非公平锁），我们以FairSync为例（NonfairSync原理类似）来说明。 从上面代码中可以看出，lock方法和unlock方法的具体实现都是由acquire和release方法完成的，而FairSync类中并没有定义acquire方法和release方法，这两个方法都是在Sync的父类AbstractQueuedSynchronizer类中实现的。 1234567891011121314151617public final void acquire(int arg) &#123; // 只关注tryAcquire即可 if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125;public final boolean release(int arg) &#123; // 只关注tryRelease即可 if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false;&#125; acquire方法的大致步骤：tryAcquire会尝试获取锁，如果获取失败会将当前线程加入等待队列，并挂起当前线程。当前线程会等待被唤醒，被唤醒后再次尝试获取锁。 release方法的大致步骤：tryRelease会尝试释放锁，如果释放成功可能会唤醒其它线程，释放失败会抛出异常。 我们可以看出，获取锁和释放锁的具体操作是在tryAcquire和tryRelease中实现的，而tryAcquire和tryRelease在父类AbstractQueuedSynchronizer中没有定义，留给子类FairSync去实现。 我们来看一下FairSync类的tryAcquire和tryRelease的具体实现： 12345678910111213141516171819202122232425262728293031323334353637383940// state变量定义在AbstractQueuedSynchronizer中，表示同步状态。private volatile int state;protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); // 读State int c = getState(); if (c == 0) &#123; // 获取到锁会写state if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) throw new Error("Maximum lock count exceeded"); // 写state setState(nextc); return true; &#125; return false;&#125;protected final boolean tryRelease(int releases) &#123; // 读state int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) &#123; free = true; setExclusiveOwnerThread(null); &#125; // 写state setState(c); return free;&#125; 从上面的代码中可以看到有一个volatile state变量，这个变量用来表示同步状态，获取锁时会先读取state的值，获取成功后会把值从0修改为1。当释放锁时，也会先读取state的值然后进行修改。也就是说，无论是成功获取到锁还是成功释放掉锁，都会先读取state变量的值，再进行修改。 我们将上面的代码做个简化，只留下关键步骤： 1234567891011private volatile int state;void lock() &#123; read state if (can get lock) write state&#125;void unlock() &#123; write state&#125; 假设线程a通过调用lock方法获取到锁，此时线程b也调用了lock方法，因为a尚未释放锁，b只能等待。a在获取锁的过程中会先读state，再写state。当a释放掉锁并唤醒b，b会尝试获取锁，也会先读state，再写state。 我们注意到上述提到的Happens-before规则的第二条： 一个volatile变量的写操作发生在这个volatile变量随后的读操作之前 可以推测出，当线程b执行获取锁操作，读取了state变量的值后，线程a在写入state变量之前的任何操作结果对线程b都是可见的。 由此，我们可以得出结论Lock接口的实现类能实现和synchronized内置锁一样的内存数据可见性。 结束语ReentrantLock及其它Lock接口实现类实现内存数据可见性的方式相对比较隐秘，借助了volatile关键字间接地实现了可见性。其实不光是Lock接口实现类，因为j.u.c包中大部分同步器的实现都是基于AbstractQueuedSynchronizer类来实现的，因此这些同步器也能够提供一定的可见性，有兴趣的同学可以尝试用类似的思路去分析。]]></content>
  </entry>
  <entry>
    <title><![CDATA[《Java并发编程实践》笔记1]]></title>
    <url>%2F2017%2F03%2F05%2F%E3%80%8AJava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B5%E3%80%8B%E7%AC%94%E8%AE%B01%2F</url>
    <content type="text"><![CDATA[并发的优点 资源利用率 公平性 便利性（不是很靠谱） 线程带来的风险 安全性问题 活跃性问题 性能问题 可见性问题Java内存模型要求变量的读取和写入都是源自的，但对于非volatile类型的64位数值变量（long和double），JVM允许其读操作和写操作分解为两个32位的操作。 加锁与可见性内置锁既保证了互斥行为，也保证了内存可见性。Lock呢？存疑 对象不可变的条件 对象创建后其状态就不能修改 对象的所有域都是final类型 对象是正确创建的（this引用没有逸出） final域final类型的变量是不可变的，但是如果final引用的对象是可变的，那么这些被引用的对象是可以修改的。不可变对象是线程安全的。 安全发布的常用模式要安全的发布一个对象，对象的引用以及对象的状态必须同时对其它线程可见。 一个正确构造的对象可以通过以下方式来安全的发布： 在静态初始化函数中初始化一个对象引用 将对象的引用保存到volatile类型的域或者AtomicReference对象中 将对象的引用保存到某个正确构造对象的final类型域中 将对象的引用保存到一个由锁保护的域中 第一条可见下面的例子，因为静态变量是在类的初始化阶段进行的，有内部同步机制： public static Holder holder = new Holder() 安全共享对象的方式 ConcurrentModificationException容器在迭代过程中被修改时，就会抛出ConcurrentModificationException。如果不希望在迭代期间对容器加锁，一种办法是克隆容器。 容器的toString，equals和hashCode方法都会迭代容器。 ConcurrentHashMap 分段锁，提高并发度 弱一致性，不会抛出ConcurrentModificationException size和isEmpty返回近似值 SynchronousQueueSynchronousQueue是一个没有数据缓冲的BlockingQueue，要将一个元素放入SynchronousQueue，必须有另一个线程正在等待接受这个元素。 FutureTaskFuture是接口，FutureTask是实现类。在1.8中FutureTask不再基于AQS实现，FutureTask的run方法会阻塞执行，get方法会等待执行完成才会返回。 栅栏线程必须同时到达栅栏位置，才能继续执行。闭锁（CountDownLatch）用于等待事件，栅栏用于等待线程（await方法） 总结 尽量将域声明为final类型，除非需要它们是可变的 不可变对象一定是线程安全的]]></content>
      <categories>
        <category>并发</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AQS注释]]></title>
    <url>%2F2017%2F03%2F02%2FAQS%E6%B3%A8%E9%87%8A%2F</url>
    <content type="text"><![CDATA[AbstractQueuedSynchronizer.java备注： node节点创建后waitStatus为0； 节点入队前如果队列是空的话，会创建一个空的头节点； 获取锁失败后会把waitStatus从0改为SIGNAL； acquire失败后会把当前节点的waitStatus从0修改为SIGNAL，无论是互斥还是共享； 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689690691692693694695696697698699700701702703704705706707708709710711712713714715716717718719720721722723724725726727728729730731732733734735736737738739740741742743744745746747748749750751752753754755756757758759760761762763764765766767768769770771772773774775776777778779780781782783784785786787788789790791792793794795796797798799800801802803804805806807808809810811812813814815816817818819820821822823824825826827828829830831832833834835836837838839840841842843844845846847848849850851852853854855856857858859860861862863864865866867868869870871872873874875876877878879880881882883884885886887888889890891892893894895896897898899900901902903904905906907908909910911912913914915916917918919920921922923924925926927928929930931932933934935936937938939940941942943944945946947948949950951952953954955956957958959960961962963964965966967968969970971972973974975976977978979980981982983984985986987988989990991992993994995996997998999100010011002100310041005100610071008100910101011101210131014101510161017101810191020102110221023102410251026102710281029103010311032103310341035103610371038103910401041104210431044104510461047104810491050105110521053105410551056105710581059106010611062106310641065106610671068106910701071107210731074107510761077107810791080108110821083108410851086108710881089109010911092109310941095109610971098109911001101110211031104110511061107110811091110111111121113111411151116111711181119112011211122112311241125112611271128112911301131113211331134113511361137113811391140114111421143114411451146114711481149115011511152115311541155115611571158115911601161116211631164116511661167116811691170117111721173117411751176117711781179118011811182118311841185118611871188118911901191119211931194119511961197119811991200120112021203120412051206120712081209121012111212121312141215121612171218121912201221122212231224122512261227122812291230123112321233123412351236123712381239124012411242124312441245124612471248124912501251125212531254125512561257125812591260126112621263126412651266126712681269127012711272127312741275127612771278127912801281128212831284128512861287128812891290129112921293129412951296129712981299130013011302130313041305130613071308130913101311131213131314131513161317131813191320132113221323132413251326132713281329133013311332133313341335133613371338133913401341134213431344134513461347134813491350135113521353135413551356135713581359136013611362136313641365136613671368136913701371137213731374137513761377137813791380138113821383138413851386138713881389139013911392139313941395139613971398139914001401140214031404140514061407140814091410141114121413141414151416141714181419142014211422142314241425142614271428142914301431143214331434143514361437143814391440144114421443144414451446144714481449145014511452145314541455145614571458145914601461146214631464146514661467146814691470147114721473147414751476147714781479148014811482148314841485148614871488148914901491149214931494149514961497149814991500150115021503150415051506150715081509151015111512151315141515151615171518151915201521152215231524152515261527152815291530153115321533153415351536153715381539154015411542154315441545154615471548154915501551155215531554155515561557155815591560156115621563156415651566156715681569157015711572157315741575157615771578157915801581158215831584158515861587158815891590159115921593159415951596159715981599160016011602160316041605160616071608160916101611161216131614161516161617161816191620162116221623162416251626162716281629163016311632163316341635163616371638163916401641164216431644164516461647164816491650165116521653165416551656165716581659166016611662166316641665166616671668166916701671167216731674167516761677167816791680168116821683168416851686168716881689169016911692169316941695169616971698169917001701170217031704170517061707170817091710171117121713171417151716171717181719172017211722172317241725172617271728172917301731173217331734173517361737173817391740174117421743174417451746174717481749175017511752175317541755175617571758175917601761176217631764176517661767176817691770177117721773177417751776177717781779178017811782178317841785178617871788178917901791179217931794179517961797179817991800180118021803180418051806180718081809181018111812181318141815181618171818181918201821182218231824182518261827182818291830183118321833183418351836183718381839184018411842184318441845184618471848184918501851185218531854185518561857185818591860186118621863186418651866186718681869187018711872187318741875187618771878187918801881188218831884188518861887188818891890189118921893189418951896189718981899190019011902190319041905190619071908190919101911191219131914191519161917191819191920192119221923192419251926192719281929193019311932193319341935193619371938193919401941194219431944194519461947194819491950195119521953195419551956195719581959196019611962196319641965196619671968196919701971197219731974package java.util.concurrent.locks;import java.util.concurrent.TimeUnit;import java.util.ArrayList;import java.util.Collection;import java.util.Date;import sun.misc.Unsafe;/** * AQS类提供了一个依赖于先入先出等待队列的可实现阻塞锁和其它同步器（信号量，事件等）的框架。这个类被设计为大多数同步器的基础 * 类，这些同步类都是依赖一个原子的int变量来表示它的状态。子类们必须通过它们定义的protected方法来修改状态，并且这个原子变量 * 的含义需要在子类中被赋予。除了对状态的操作，AQS类中的其它方法处理索引的队列和阻塞机制。子类们可以保留其它状态变量，但是只有 * 通过getState，setState和compareAndSetState操作的变量才能被用于同步机制。 * * 继承自AQS类的子类应该被定义为非public的内部类，在这个内部类中去实现同步机制。AQS类没有实现任何同步器接口，相反它提供了类似 * acquireInterruptibly这样的方法，这样的方法可以被子类用于实现它们的public方法。 * * AQS类既支持互斥模式也支持共享模式。当在互斥模式下进行acquire操作时，只有一个线程能成功，多线程在共享模式下进行acquire操作 * 可能会成功。AQS类提供了当一个共享状态的acquire操作成功后，下一个等待线程（如果有的话）必须决定它是否也能获取成功。不同状态的 * 等待线程使用相同的FIFO队列。一般情况下，子类们只支持一种模式（共享或互斥），但是也有例外情况，比如ReadWriteLock。只支持某一 * 种状态的子类不用实现另一种模式的方法。 * * AQS类定义了一个ConditionObject的嵌套类，可以用作Condition的实现。AbstractQueuedSynchronizer.ConditionObject的行为 * 当然取决于它的同步器实现的语义。 * * AQS类为内部队列提供检查，检测和监视方法，并且对condition对象也提供了类似方法。 这些方法可以使用AbstractQueuedSynchronizer * 的同步机制根据需要导出到子类中。 * * 这个类序列化后只存储底层原子整数维护状态，因此反序列化后对象的队列是空的。 需要可序列化的子类可以定义一个readObject方法，该方法在 * 反序列化后将其恢复到一个已知的初始状态。 * * 用法： * 要使用此类作为同步器的基础，请通过使用getState（），setState（int）或compareAndSetState（int，int）来检查或修改同步状态，并重新定义以下方法： * tryAcquire(int) * tryRelease(int) * tryAcquireShared(int) * tryReleaseShared(int) * isHeldExclusively() * 上面的方法默认会抛出UnsupportedOperationException，这些方法的实现必须是线程安全的，而且应当比较短小和保持非阻塞。对于使用AQS的 * 类而言，实现这些方法是唯一要做的事情，其它的方法都被定义为了final，不能被更改。 * * 你可能也注意到了继承自AQS类的方法可以用来跟踪哪个线程保持有互斥的同步器。鼓励你们去使用它们--这能够提供检测和诊断的工具来决定哪个线 * 程应该持有锁。 * * 即使AQS类是基于一个内部的FIFO队列，它并不强制使用FIFO的获取策略。互斥操作的核心操作如下所示： * Acquire: * while (!tryAcquire(arg)) &#123; * enqueue thread if it is not already queued; * possibly block current thread; * &#125; * * Release: * if (tryRelease(arg)) * unblock the first queued thread; * * （共享模式的操作也是类似的，不过可能会触发级联的信号） * * 因为在入队之前会先进行检测，一个新的获取线程可能比队列中阻塞的线程提前到达。但是，如果你想的话，可以定 * 义tryAcquire或tryAcquireShared方法禁止这种操作，从而提供一个公平的FIFO的获取顺序。尤其，大多数同步器 * 可以定义tryAcquire方法返回false如果hasQueuedPredecessors（一个特意为实现公平同步器而设计的方法） * 返回true的话。其它的变种方法也是允许的。 * * 吞吐量和可扩展性是抢占策略的目标。虽然这不能保证是公平的或无饥饿的，早期的排队线程被允许在后面排队的线程 * 之前执行竞争操作，每次和闯入线程的重新竞争都是公平的。并且，虽然acquire操作并不自旋，但是有可能在被阻塞 * 前多次执行tryAcquire操作。这提供了自旋的最大优点，当互斥只是短暂持有，如果是长期持有，不会有带来太大的副 * 作用。如果有需要，你也可以在调用acquire操作时通过hasContended或者hasQueuedThreads来快速的进行检查， * 如果同步器的竞争并不激烈。 * * AQS类通过一个能够依赖的支持许多状态的state变量，acquire和release方法可以在调用时设置参数，还有 * 一个内置的FIFO等待队列提供了一个有效并且具有可扩展性的同步器基础类。如果这不足以支持你的需求，你可 * 以通过atomic类，LockSupport类和自定义的队列来创建自己的同步器。 * * 用例 * * 这里是一个非重入互斥锁类，它使用值零表示解锁状态，一个表示锁定状态。 虽然不可重入锁并不严格要求记录当前所 * 有者线程，但是这个类仍然这样做，使得更容易监视使用。 它还支持condition并暴露了操作方法： * * public class Mutex implements Lock, java.io.Serializable &#123; * * // Our internal helper class * private static class Sync extends AbstractQueuedSynchronizer &#123; * // 是否处于锁定状态 * protected boolean isHeldExclusively() &#123; * return getState() == 1; * &#125; * * // 获取锁如果state为0 * public boolean tryAcquire(int acquires) &#123; * assert acquires == 1; // Otherwise unused * if (compareAndSetState(0, 1)) &#123; * setExclusiveOwnerThread(Thread.currentThread()); * return true; * &#125; * return false; * &#125; * * // 通过把state设置为0释放锁 * protected boolean tryRelease(int releases) &#123; * assert releases == 1; // Otherwise unused * if (getState() == 0) throw new IllegalMonitorStateException(); * setExclusiveOwnerThread(null); * setState(0); * return true; * &#125; * * // 提供condition * Condition newCondition() &#123; return new ConditionObject(); &#125; * * // 反序列化属性 * private void readObject(ObjectInputStream s) * throws IOException, ClassNotFoundException &#123; * s.defaultReadObject(); * setState(0); // 设置为没有锁状态 * &#125; * &#125; * * // The sync object does all the hard work. We just forward to it. * private final Sync sync = new Sync(); * * public void lock() &#123; sync.acquire(1); &#125; * public boolean tryLock() &#123; return sync.tryAcquire(1); &#125; * public void unlock() &#123; sync.release(1); &#125; * public Condition newCondition() &#123; return sync.newCondition(); &#125; * public boolean isLocked() &#123; return sync.isHeldExclusively(); &#125; * public boolean hasQueuedThreads() &#123; return sync.hasQueuedThreads(); &#125; * public void lockInterruptibly() throws InterruptedException &#123; * sync.acquireInterruptibly(1); * &#125; * public boolean tryLock(long timeout, TimeUnit unit) * throws InterruptedException &#123; * return sync.tryAcquireNanos(1, unit.toNanos(timeout)); * &#125; * &#125; * * 这里是一个类似于CountDownLatch的锁类，除了它只需要一个单一的信号。 因为锁存器是非排他的，它使用共享的获取和释放方法。 * * class BooleanLatch &#123; * * private static class Sync extends AbstractQueuedSynchronizer &#123; * boolean isSignalled() &#123; return getState() != 0; &#125; * * protected int tryAcquireShared(int ignore) &#123; * return isSignalled() ? 1 : -1; * &#125; * * protected boolean tryReleaseShared(int ignore) &#123; * setState(1); * return true; * &#125; * &#125; * * private final Sync sync = new Sync(); * public boolean isSignalled() &#123; return sync.isSignalled(); &#125; * public void signal() &#123; sync.releaseShared(1); &#125; * public void await() throws InterruptedException &#123; * sync.acquireSharedInterruptibly(1); * &#125; * &#125; * * 启示版本：1.5 * 作者：Doug Lea */public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer implements java.io.Serializable &#123; private static final long serialVersionUID = 7373984972572414691L; /** * 创建一个新的初始同步状态为0的AQS实例 */ protected AbstractQueuedSynchronizer() &#123; &#125; /** * 等待队列中的节点类 * * AQS中的等待队列是CLH锁队列的一个变种。CLH锁通常被用于实现自旋锁。相对于在互斥同步器中的使用，我们使用相同的机 * 制来保存一个线程的前置节点的控制信息。每个节点中的status变量用于表示这个线程是否应该被阻塞。每个节点在其前置节点 * 释放之后会收到通知。每个节点都是一个等待线程的监视器。status变量并不控制这个线程是否获得了锁。一个线程可能会在它是 * 等待队列中的第一个时去执行acquire操作，但是，这并不保证能够成功。这只提供了一个竞争的机会。所以可能还会重新进入等待状态。 * * 当一个新节点入队CLH lock时，它会自动的被放在队尾的位置。出队只需要设置head变量。 * * +------+ prev +-----+ +-----+ * head | | &lt;---- | | &lt;---- | | tail * +------+ +-----+ +-----+ * * CLH队列的入队操作是需要对tail做一次原子操作，因此有一个简单的从未排队到排队的原子分界点。 * 类似的，出队只需要更新head的值。但是，在获得后继节点时需要做一些更多的工作，用于可能的取消情况因为超时或 * 中断操作。 * * prev引用主要用于处理取消操作。如果一个节点被取消了，它的后继节点会被连接到一个没有取消的前置节点。 * * 我们也使用next引用来实现阻塞机制。每个线程的节点中保存着线程的id，所以一个前置节点会遍历它的后继节点 * 来决定应该唤醒哪个线程。决定后继节点时必须避免与新入队的节点设置next变量发生竞争。当一个节点的后继节点 * 是null时，通过从原子更新的“尾部”向后检查来解决这个问题。（换句话说，next链接是对我们向后遍历的一种优化） * * 取消为基本算法引入了一些保守性。由于我们必须轮询其他节点的取消，所以我们可能会没有注意到 * 一个被取消的节点是否在我们之前或之后。处理方法是当取消发生时，唤醒后继节点，允许他们发现 * 新的前置节点，除非我们能找到一个没有被取消的前置节点担当起这个责任。 * * CLH队列需要一个虚拟的头节点。头结点会在需要的时候才会被创建。 * * Condition中的等待线程也会使用这些节点，但是，使用另外一种方式。Conditions只需要一个普通的 * 基于链表的队列，因为他们只会被互斥地持有。当await时，一个节点会被插入condition队列，当sigal * 时，这个节点会被转移到主队列中。status变量的某一个值会被用来指明这个节点处在哪个队列。 * */ static final class Node &#123; /** 标识节点是否是共享节点 */ static final Node SHARED = new Node(); /** 标识节点是否是互斥节点 */ static final Node EXCLUSIVE = null; /** 线程是否被取消 */ static final int CANCELLED = 1; /** 后继节点的线程是否需要唤醒 */ static final int SIGNAL = -1; /** 线程是否在condition队列里 */ static final int CONDITION = -2; /** 下一次acquireShared是否无条件向后传播 */ static final int PROPAGATE = -3; /** * waitStatus的值只能是以下的这些： * * SIGNAL： 当前节点的后继节点（很快会）已经被阻塞，当前节点必须唤醒 * 它的后继节点当它release或者cancel的时候。为了避免竞争 * acquire方法必须标明他们需要一个signal，然后它们会尝试 * 原子acquire操作，如果失败的话，会被阻塞。 * CANCELLED: 当前节点因为超时或者中断被取消。这是最终状态，不会再改变。 * 尤其，一个cancelled的节点永不会被阻塞。 * CONDITION：当前节点在Condition的队列中。除非再转移，否则不会被用作 * 一个同步队列节点。它的状态会被设置为0。 * PROPAGATE：一个释放的共享节点应该向后传递给其它节点。这个状态是在 * doReleaseShared操作被执行的，能够保证这个状态继续传递。 * 0 ：无特殊意义 * 这个变量为了简单实用被设置为数字类型。非负数表明这个节点不需要signal。 * 所以大多数代码不需要检查这个变量的值。 * * 这个变量被初始化为0，当作普通同步节点时，当为condition的节点时，被设置为 * CONDITION。通过CAS修改这个变量的值。 */ volatile int waitStatus; /** * 当前节点的前缀节点，在入队时被赋值，在出队时设置为null（for gc）。当 * 前缀节点被取消时，我们会短时间自旋寻找一个没有被取消的前缀节点，这肯定会存在， * 因为头节点永远不会被取消。一个节点只有在成功acquire后才能成为head节点。 * 一个被取消的消除永远不会acquire成功，而且一个线程只能取消它自己。 */ volatile Node prev; /** * 当前节点的后缀节点。在入队时赋值，在有节点取消时可能会调整，出队时会被 * 设置为null（for gc）。入队操作并不会设置next的值，只有在连接时才会。 * 所以看到一个next域为null的节点并不意味着这个节点就是队尾节点。但是， * 如果一个节点的next是null，我们可以从tail向前扫描，做双重检查。被取消 * 的节点的next的值会被设置成它自己本身。 */ volatile Node next; /** * 节点对应的线程，在构造方法中初始化，没有用之后会被设置为null */ volatile Thread thread; /** * 指向condition队列/共享节点的下个节点。因为condition队列只会在互斥状态下 * 被访问，我们只需要一个简单的基于链表的队列来保存condition的等待节点。它们 * 会被转移到CLH队列，当重新acquire时。因为condition只能在互斥状态下使用， * 我们通过使用特殊的值来表示共享模式。 */ Node nextWaiter; /** * 如果节点是SHARED状态，返回true */ final boolean isShared() &#123; return nextWaiter == SHARED; &#125; /** * 返回前置节点 */ final Node predecessor() throws NullPointerException &#123; Node p = prev; if (p == null) throw new NullPointerException(); else return p; &#125; Node() &#123; // 初始化head节点或者SHARED节点 &#125; Node(Thread thread, Node mode) &#123; // addWaiter方法调用 this.nextWaiter = mode; this.thread = thread; &#125; Node(Thread thread, int waitStatus) &#123; // Condition类使用 this.waitStatus = waitStatus; this.thread = thread; &#125; &#125; /** * 等待队列头节点，延迟初始化。除了初始化过程，head的值只能用setHead方法修改。 * 备注：如果head节点存在，它的waitStatus状态必定不为CANCELLED */ private transient volatile Node head; /** * 等待队列尾，延迟初始化。只会在新节点入队时被修改。 */ private transient volatile Node tail; /** * 同步状态 */ private volatile int state; protected final int getState() &#123; return state; &#125; protected final void setState(int newState) &#123; state = newState; &#125; /** * 原子更新state的值 */ protected final boolean compareAndSetState(int expect, int update) &#123; return unsafe.compareAndSwapInt(this, stateOffset, expect, update); &#125; // 队列工具 /** * 自旋时间变量，自旋比固定时间休眠效率更快。这是个粗略估计的值，但是足以提高响应时间。 */ static final long spinForTimeoutThreshold = 1000L; /** * 将节点写入队列， 如果有必要就进行初始化 * node：将要入队的节点 * 返回：节点的前置节点 */ private Node enq(final Node node) &#123; for (;;) &#123; Node t = tail; if (t == null) &#123; // tail为null证明没有等待节点，此时必须初始化head节点 if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; // tail不为null，设置当前节点的前置节点为tail node.prev = t; // 通过CAS设置tail为node if (compareAndSetTail(t, node)) &#123; // 之前的tail节点的后缀节点指向node t.next = node; return t; &#125; &#125; &#125; &#125; /** * 创建当前线程对应的等待节点，设置其模式（互斥或共享），并入队。 */ private Node addWaiter(Node mode) &#123; // 初始化节点 Node node = new Node(Thread.currentThread(), mode); // 通过CAS快速入队，失败后再调用enq方法 Node pred = tail; if (pred != null) &#123; node.prev = pred; if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; enq(node); return node; &#125; /** * 设置队列头结点， 只在acquire方法中被调用。设置无用的域为null（for gc）。 */ private void setHead(Node node) &#123; head = node; node.thread = null; node.prev = null; &#125; /** * 唤醒节点的后继节点，如果存在的话。 */ private void unparkSuccessor(Node node) &#123; /* * If status is negative (i.e., possibly needing signal) try * to clear in anticipation of signalling. It is OK if this * fails or if status is changed by waiting thread. */ /** * 没太明白目的是什么 */ int ws = node.waitStatus; if (ws &lt; 0) // CAS设置waitStatus compareAndSetWaitStatus(node, ws, 0); /* * Thread to unpark is held in successor, which is normally * just the next node. But if cancelled or apparently null, * traverse backwards from tail to find the actual * non-cancelled successor. */ /** * 给当前节点的后置节点找到合适的前置节点，如果需要的话。因为它的前置节点可能 * 被取消了，或者没有正确设置后置节点（初始化为null） */ Node s = node.next; // waitStatus &gt; 0表示CANCELLED if (s == null || s.waitStatus &gt; 0) &#123; s = null; // 从tail向前遍历 for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) // 找到了没有CANCELLED节点，设置后置节点 if (t.waitStatus &lt;= 0) s = t; &#125; if (s != null) // 唤醒 LockSupport.unpark(s.thread); &#125; /** * 释放共享节点--通知后置节点并且保证传播下去。（对于互斥节点，release操作只需要 * 调用head节点的unparkSuccessor方法如果需要的话，不一定需要比如可重入锁）。 * */ private void doReleaseShared() &#123; /** * 确保release操作向后传播，即使同时又acquire和release操作在进行。 * 通常的方式是唤醒head节点的后置节点，如果需要的话。但是并不是，status被 * 设置为PROPAGATE保证了当release时传播能够继续进行。另外，我们必须循环进行 * 当我们正在进行release时有新的节点添加进来。而且，不同于其它unparkSuccessor的用法， * 我们需要知道CAS status是否失败，失败的话需要进行重试 */ for (;;) &#123; Node h = head; if (h != null &amp;&amp; h != tail) &#123; int ws = h.waitStatus; // 从SIGNAL改为0的目的是下一次循环从0改为PROPAGATE if (ws == Node.SIGNAL) &#123; if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; // loop to recheck cases unparkSuccessor(h); &#125; else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; // loop on failed CAS &#125; if (h == head) // loop if head changed break; &#125; &#125; /** * Sets head of queue, and checks if successor may be waiting * in shared mode, if so propagating if either propagate &gt; 0 or * PROPAGATE status was set. * * @param node the node * @param propagate the return value from a tryAcquireShared */ /** * 设置队列头，如果后继节点处于共享状态，并且propagate大于0时会向后传播， * 也就是release下一个节点(CountDownLatch而言，propagate始终大于0)， * 暂时没发现不继续向后传播的例子。 */ private void setHeadAndPropagate(Node node, int propagate) &#123; Node h = head; // Record old head for check below setHead(node); /* * Try to signal next queued node if: * Propagation was indicated by caller, * or was recorded (as h.waitStatus either before * or after setHead) by a previous operation * (note: this uses sign-check of waitStatus because * PROPAGATE status may transition to SIGNAL.) * and * The next node is waiting in shared mode, * or we don't know, because it appears null * * The conservatism in both of these checks may cause * unnecessary wake-ups, but only when there are multiple * racing acquires/releases, so most need signals now or soon * anyway. */ if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0 || (h = head) == null || h.waitStatus &lt; 0) &#123; Node s = node.next; if (s == null || s.isShared()) doReleaseShared(); &#125; &#125; // Utilities for various versions of acquire /** * 取消进行中的acquire */ private void cancelAcquire(Node node) &#123; // Ignore if node doesn't exist if (node == null) return; node.thread = null; // Skip cancelled predecessors Node pred = node.prev; while (pred.waitStatus &gt; 0) node.prev = pred = pred.prev; // predNext is the apparent node to unsplice. CASes below will // fail if not, in which case, we lost race vs another cancel // or signal, so no further action is necessary. Node predNext = pred.next; // Can use unconditional write instead of CAS here. // After this atomic step, other Nodes can skip past us. // Before, we are free of interference from other threads. node.waitStatus = Node.CANCELLED; // If we are the tail, remove ourselves. if (node == tail &amp;&amp; compareAndSetTail(node, pred)) &#123; compareAndSetNext(pred, predNext, null); &#125; else &#123; // If successor needs signal, try to set pred's next-link // so it will get one. Otherwise wake it up to propagate. int ws; if (pred != head &amp;&amp; ((ws = pred.waitStatus) == Node.SIGNAL || (ws &lt;= 0 &amp;&amp; compareAndSetWaitStatus(pred, ws, Node.SIGNAL))) &amp;&amp; pred.thread != null) &#123; Node next = node.next; if (next != null &amp;&amp; next.waitStatus &lt;= 0) compareAndSetNext(pred, predNext, next); &#125; else &#123; unparkSuccessor(node); &#125; node.next = node; // help GC &#125; &#125; /** * Checks and updates status for a node that failed to acquire. * Returns true if thread should block. This is the main signal * control in all acquire loops. Requires that pred == node.prev. * 当tryAcquire失败后会调用，用来判断当前线程是否应该被挂起。 */ private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; int ws = pred.waitStatus; if (ws == Node.SIGNAL) /* * This node has already set status asking a release * to signal it, so it can safely park. * 一般不会第一次就到这，第一次应该都是0 */ return true; if (ws &gt; 0) &#123; /* * Predecessor was cancelled. Skip over predecessors and * indicate retry. * 找到真正的前置节点 */ do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; /* * waitStatus must be 0 or PROPAGATE. Indicate that we * need a signal, but don't park yet. Caller will need to * retry to make sure it cannot acquire before parking. * 不太懂为啥要这么做 */ compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false; &#125; static void selfInterrupt() &#123; Thread.currentThread().interrupt(); &#125; /** * Convenience method to park and then check if interrupted * * @return &#123;@code true&#125; if interrupted */ private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); return Thread.interrupted(); &#125; /* * Various flavors of acquire, varying in exclusive/shared and * control modes. Each is mostly the same, but annoyingly * different. Only a little bit of factoring is possible due to * interactions of exception mechanics (including ensuring that we * cancel if tryAcquire throws exception) and other control, at * least not without hurting performance too much. */ /** * Acquires in exclusive uninterruptible mode for thread already in * queue. Used by condition wait methods as well as acquire. * * @param node the node * @param arg the acquire argument * @return &#123;@code true&#125; if interrupted while waiting */ final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; // 如果前置节点是头节点，尝试获取一次，不成功再park，可能为了性能着想 final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; // 获取成功 setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; // 获取失败被挂起 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125; &#125; /** * Acquires in exclusive interruptible mode. * @param arg the acquire argument */ private void doAcquireInterruptibly(int arg) throws InterruptedException &#123; final Node node = addWaiter(Node.EXCLUSIVE); boolean failed = true; try &#123; for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125; &#125; /** * Acquires in exclusive timed mode. * * @param arg the acquire argument * @param nanosTimeout max wait time * @return &#123;@code true&#125; if acquired */ private boolean doAcquireNanos(int arg, long nanosTimeout) throws InterruptedException &#123; if (nanosTimeout &lt;= 0L) return false; final long deadline = System.nanoTime() + nanosTimeout; final Node node = addWaiter(Node.EXCLUSIVE); boolean failed = true; try &#123; for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return true; &#125; nanosTimeout = deadline - System.nanoTime(); if (nanosTimeout &lt;= 0L) return false; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; nanosTimeout &gt; spinForTimeoutThreshold) LockSupport.parkNanos(this, nanosTimeout); if (Thread.interrupted()) throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125; &#125; /** * Acquires in shared uninterruptible mode. * @param arg the acquire argument */ private void doAcquireShared(int arg) &#123; final Node node = addWaiter(Node.SHARED); boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); if (p == head) &#123; int r = tryAcquireShared(arg); if (r &gt;= 0) &#123; setHeadAndPropagate(node, r); p.next = null; // help GC if (interrupted) selfInterrupt(); failed = false; return; &#125; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125; &#125; /** * Acquires in shared interruptible mode. * @param arg the acquire argument */ private void doAcquireSharedInterruptibly(int arg) throws InterruptedException &#123; final Node node = addWaiter(Node.SHARED); boolean failed = true; try &#123; for (;;) &#123; final Node p = node.predecessor(); if (p == head) &#123; int r = tryAcquireShared(arg); if (r &gt;= 0) &#123; setHeadAndPropagate(node, r); p.next = null; // help GC failed = false; return; &#125; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125; &#125; /** * Acquires in shared timed mode. * * @param arg the acquire argument * @param nanosTimeout max wait time * @return &#123;@code true&#125; if acquired */ private boolean doAcquireSharedNanos(int arg, long nanosTimeout) throws InterruptedException &#123; if (nanosTimeout &lt;= 0L) return false; final long deadline = System.nanoTime() + nanosTimeout; final Node node = addWaiter(Node.SHARED); boolean failed = true; try &#123; for (;;) &#123; final Node p = node.predecessor(); if (p == head) &#123; int r = tryAcquireShared(arg); if (r &gt;= 0) &#123; setHeadAndPropagate(node, r); p.next = null; // help GC failed = false; return true; &#125; &#125; nanosTimeout = deadline - System.nanoTime(); if (nanosTimeout &lt;= 0L) return false; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; nanosTimeout &gt; spinForTimeoutThreshold) LockSupport.parkNanos(this, nanosTimeout); if (Thread.interrupted()) throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125; &#125; // Main exported methods /** * 留给子类实现，子类中会定义state变量的具体含义 */ protected boolean tryAcquire(int arg) &#123; throw new UnsupportedOperationException(); &#125; /** * tryRelease同理 */ protected boolean tryRelease(int arg) &#123; throw new UnsupportedOperationException(); &#125; /** * 尝试获取共享锁 */ protected int tryAcquireShared(int arg) &#123; throw new UnsupportedOperationException(); &#125; protected boolean tryReleaseShared(int arg) &#123; throw new UnsupportedOperationException(); &#125; protected boolean isHeldExclusively() &#123; throw new UnsupportedOperationException(); &#125; /** * lock方法的具体实现 */ public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); &#125; /** * Acquires in exclusive mode, aborting if interrupted. * Implemented by first checking interrupt status, then invoking * at least once &#123;@link #tryAcquire&#125;, returning on * success. Otherwise the thread is queued, possibly repeatedly * blocking and unblocking, invoking &#123;@link #tryAcquire&#125; * until success or the thread is interrupted. This method can be * used to implement method &#123;@link Lock#lockInterruptibly&#125;. * * @param arg the acquire argument. This value is conveyed to * &#123;@link #tryAcquire&#125; but is otherwise uninterpreted and * can represent anything you like. * @throws InterruptedException if the current thread is interrupted */ public final void acquireInterruptibly(int arg) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); if (!tryAcquire(arg)) doAcquireInterruptibly(arg); &#125; /** * Attempts to acquire in exclusive mode, aborting if interrupted, * and failing if the given timeout elapses. Implemented by first * checking interrupt status, then invoking at least once &#123;@link * #tryAcquire&#125;, returning on success. Otherwise, the thread is * queued, possibly repeatedly blocking and unblocking, invoking * &#123;@link #tryAcquire&#125; until success or the thread is interrupted * or the timeout elapses. This method can be used to implement * method &#123;@link Lock#tryLock(long, TimeUnit)&#125;. * * @param arg the acquire argument. This value is conveyed to * &#123;@link #tryAcquire&#125; but is otherwise uninterpreted and * can represent anything you like. * @param nanosTimeout the maximum number of nanoseconds to wait * @return &#123;@code true&#125; if acquired; &#123;@code false&#125; if timed out * @throws InterruptedException if the current thread is interrupted */ public final boolean tryAcquireNanos(int arg, long nanosTimeout) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); return tryAcquire(arg) || doAcquireNanos(arg, nanosTimeout); &#125; /** * Releases in exclusive mode. Implemented by unblocking one or * more threads if &#123;@link #tryRelease&#125; returns true. * This method can be used to implement method &#123;@link Lock#unlock&#125;. * * @param arg the release argument. This value is conveyed to * &#123;@link #tryRelease&#125; but is otherwise uninterpreted and * can represent anything you like. * @return the value returned from &#123;@link #tryRelease&#125; */ public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false; &#125; /** * Acquires in shared mode, ignoring interrupts. Implemented by * first invoking at least once &#123;@link #tryAcquireShared&#125;, * returning on success. Otherwise the thread is queued, possibly * repeatedly blocking and unblocking, invoking &#123;@link * #tryAcquireShared&#125; until success. * * @param arg the acquire argument. This value is conveyed to * &#123;@link #tryAcquireShared&#125; but is otherwise uninterpreted * and can represent anything you like. */ public final void acquireShared(int arg) &#123; if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg); &#125; /** * Acquires in shared mode, aborting if interrupted. Implemented * by first checking interrupt status, then invoking at least once * &#123;@link #tryAcquireShared&#125;, returning on success. Otherwise the * thread is queued, possibly repeatedly blocking and unblocking, * invoking &#123;@link #tryAcquireShared&#125; until success or the thread * is interrupted. * @param arg the acquire argument. * This value is conveyed to &#123;@link #tryAcquireShared&#125; but is * otherwise uninterpreted and can represent anything * you like. * @throws InterruptedException if the current thread is interrupted */ public final void acquireSharedInterruptibly(int arg) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); if (tryAcquireShared(arg) &lt; 0) doAcquireSharedInterruptibly(arg); &#125; /** * Attempts to acquire in shared mode, aborting if interrupted, and * failing if the given timeout elapses. Implemented by first * checking interrupt status, then invoking at least once &#123;@link * #tryAcquireShared&#125;, returning on success. Otherwise, the * thread is queued, possibly repeatedly blocking and unblocking, * invoking &#123;@link #tryAcquireShared&#125; until success or the thread * is interrupted or the timeout elapses. * * @param arg the acquire argument. This value is conveyed to * &#123;@link #tryAcquireShared&#125; but is otherwise uninterpreted * and can represent anything you like. * @param nanosTimeout the maximum number of nanoseconds to wait * @return &#123;@code true&#125; if acquired; &#123;@code false&#125; if timed out * @throws InterruptedException if the current thread is interrupted */ public final boolean tryAcquireSharedNanos(int arg, long nanosTimeout) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); return tryAcquireShared(arg) &gt;= 0 || doAcquireSharedNanos(arg, nanosTimeout); &#125; /** * Releases in shared mode. Implemented by unblocking one or more * threads if &#123;@link #tryReleaseShared&#125; returns true. * * @param arg the release argument. This value is conveyed to * &#123;@link #tryReleaseShared&#125; but is otherwise uninterpreted * and can represent anything you like. * @return the value returned from &#123;@link #tryReleaseShared&#125; */ public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123; doReleaseShared(); return true; &#125; return false; &#125; // Queue inspection methods /** * Queries whether any threads are waiting to acquire. Note that * because cancellations due to interrupts and timeouts may occur * at any time, a &#123;@code true&#125; return does not guarantee that any * other thread will ever acquire. * * &lt;p&gt;In this implementation, this operation returns in * constant time. * * @return &#123;@code true&#125; if there may be other threads waiting to acquire */ public final boolean hasQueuedThreads() &#123; return head != tail; &#125; /** * Queries whether any threads have ever contended to acquire this * synchronizer; that is if an acquire method has ever blocked. * * &lt;p&gt;In this implementation, this operation returns in * constant time. * * @return &#123;@code true&#125; if there has ever been contention */ public final boolean hasContended() &#123; return head != null; &#125; /** * Returns the first (longest-waiting) thread in the queue, or * &#123;@code null&#125; if no threads are currently queued. * * &lt;p&gt;In this implementation, this operation normally returns in * constant time, but may iterate upon contention if other threads are * concurrently modifying the queue. * * @return the first (longest-waiting) thread in the queue, or * &#123;@code null&#125; if no threads are currently queued */ public final Thread getFirstQueuedThread() &#123; // handle only fast path, else relay return (head == tail) ? null : fullGetFirstQueuedThread(); &#125; /** * Version of getFirstQueuedThread called when fastpath fails */ private Thread fullGetFirstQueuedThread() &#123; /* * The first node is normally head.next. Try to get its * thread field, ensuring consistent reads: If thread * field is nulled out or s.prev is no longer head, then * some other thread(s) concurrently performed setHead in * between some of our reads. We try this twice before * resorting to traversal. */ Node h, s; Thread st; if (((h = head) != null &amp;&amp; (s = h.next) != null &amp;&amp; s.prev == head &amp;&amp; (st = s.thread) != null) || ((h = head) != null &amp;&amp; (s = h.next) != null &amp;&amp; s.prev == head &amp;&amp; (st = s.thread) != null)) return st; /* * Head's next field might not have been set yet, or may have * been unset after setHead. So we must check to see if tail * is actually first node. If not, we continue on, safely * traversing from tail back to head to find first, * guaranteeing termination. */ Node t = tail; Thread firstThread = null; while (t != null &amp;&amp; t != head) &#123; Thread tt = t.thread; if (tt != null) firstThread = tt; t = t.prev; &#125; return firstThread; &#125; /** * Returns true if the given thread is currently queued. * * &lt;p&gt;This implementation traverses the queue to determine * presence of the given thread. * * @param thread the thread * @return &#123;@code true&#125; if the given thread is on the queue * @throws NullPointerException if the thread is null */ public final boolean isQueued(Thread thread) &#123; if (thread == null) throw new NullPointerException(); for (Node p = tail; p != null; p = p.prev) if (p.thread == thread) return true; return false; &#125; /** * Returns &#123;@code true&#125; if the apparent first queued thread, if one * exists, is waiting in exclusive mode. If this method returns * &#123;@code true&#125;, and the current thread is attempting to acquire in * shared mode (that is, this method is invoked from &#123;@link * #tryAcquireShared&#125;) then it is guaranteed that the current thread * is not the first queued thread. Used only as a heuristic in * ReentrantReadWriteLock. */ final boolean apparentlyFirstQueuedIsExclusive() &#123; Node h, s; return (h = head) != null &amp;&amp; (s = h.next) != null &amp;&amp; !s.isShared() &amp;&amp; s.thread != null; &#125; /** * Queries whether any threads have been waiting to acquire longer * than the current thread. * * &lt;p&gt;An invocation of this method is equivalent to (but may be * more efficient than): * &lt;pre&gt; &#123;@code * getFirstQueuedThread() != Thread.currentThread() &amp;&amp; * hasQueuedThreads()&#125;&lt;/pre&gt; * * &lt;p&gt;Note that because cancellations due to interrupts and * timeouts may occur at any time, a &#123;@code true&#125; return does not * guarantee that some other thread will acquire before the current * thread. Likewise, it is possible for another thread to win a * race to enqueue after this method has returned &#123;@code false&#125;, * due to the queue being empty. * * &lt;p&gt;This method is designed to be used by a fair synchronizer to * avoid &lt;a href="AbstractQueuedSynchronizer#barging"&gt;barging&lt;/a&gt;. * Such a synchronizer's &#123;@link #tryAcquire&#125; method should return * &#123;@code false&#125;, and its &#123;@link #tryAcquireShared&#125; method should * return a negative value, if this method returns &#123;@code true&#125; * (unless this is a reentrant acquire). For example, the &#123;@code * tryAcquire&#125; method for a fair, reentrant, exclusive mode * synchronizer might look like this: * * &lt;pre&gt; &#123;@code * protected boolean tryAcquire(int arg) &#123; * if (isHeldExclusively()) &#123; * // A reentrant acquire; increment hold count * return true; * &#125; else if (hasQueuedPredecessors()) &#123; * return false; * &#125; else &#123; * // try to acquire normally * &#125; * &#125;&#125;&lt;/pre&gt; * * @return &#123;@code true&#125; if there is a queued thread preceding the * current thread, and &#123;@code false&#125; if the current thread * is at the head of the queue or the queue is empty * @since 1.7 */ public final boolean hasQueuedPredecessors() &#123; // The correctness of this depends on head being initialized // before tail and on head.next being accurate if the current // thread is first in queue. Node t = tail; // Read fields in reverse initialization order Node h = head; Node s; return h != t &amp;&amp; ((s = h.next) == null || s.thread != Thread.currentThread()); &#125; // Instrumentation and monitoring methods /** * Returns an estimate of the number of threads waiting to * acquire. The value is only an estimate because the number of * threads may change dynamically while this method traverses * internal data structures. This method is designed for use in * monitoring system state, not for synchronization * control. * * @return the estimated number of threads waiting to acquire */ public final int getQueueLength() &#123; int n = 0; for (Node p = tail; p != null; p = p.prev) &#123; if (p.thread != null) ++n; &#125; return n; &#125; /** * Returns a collection containing threads that may be waiting to * acquire. Because the actual set of threads may change * dynamically while constructing this result, the returned * collection is only a best-effort estimate. The elements of the * returned collection are in no particular order. This method is * designed to facilitate construction of subclasses that provide * more extensive monitoring facilities. * * @return the collection of threads */ public final Collection&lt;Thread&gt; getQueuedThreads() &#123; ArrayList&lt;Thread&gt; list = new ArrayList&lt;Thread&gt;(); for (Node p = tail; p != null; p = p.prev) &#123; Thread t = p.thread; if (t != null) list.add(t); &#125; return list; &#125; /** * Returns a collection containing threads that may be waiting to * acquire in exclusive mode. This has the same properties * as &#123;@link #getQueuedThreads&#125; except that it only returns * those threads waiting due to an exclusive acquire. * * @return the collection of threads */ public final Collection&lt;Thread&gt; getExclusiveQueuedThreads() &#123; ArrayList&lt;Thread&gt; list = new ArrayList&lt;Thread&gt;(); for (Node p = tail; p != null; p = p.prev) &#123; if (!p.isShared()) &#123; Thread t = p.thread; if (t != null) list.add(t); &#125; &#125; return list; &#125; /** * Returns a collection containing threads that may be waiting to * acquire in shared mode. This has the same properties * as &#123;@link #getQueuedThreads&#125; except that it only returns * those threads waiting due to a shared acquire. * * @return the collection of threads */ public final Collection&lt;Thread&gt; getSharedQueuedThreads() &#123; ArrayList&lt;Thread&gt; list = new ArrayList&lt;Thread&gt;(); for (Node p = tail; p != null; p = p.prev) &#123; if (p.isShared()) &#123; Thread t = p.thread; if (t != null) list.add(t); &#125; &#125; return list; &#125; /** * Returns a string identifying this synchronizer, as well as its state. * The state, in brackets, includes the String &#123;@code "State ="&#125; * followed by the current value of &#123;@link #getState&#125;, and either * &#123;@code "nonempty"&#125; or &#123;@code "empty"&#125; depending on whether the * queue is empty. * * @return a string identifying this synchronizer, as well as its state */ public String toString() &#123; int s = getState(); String q = hasQueuedThreads() ? "non" : ""; return super.toString() + "[State = " + s + ", " + q + "empty queue]"; &#125; // Internal support methods for Conditions /** * Returns true if a node, always one that was initially placed on * a condition queue, is now waiting to reacquire on sync queue. * @param node the node * @return true if is reacquiring */ final boolean isOnSyncQueue(Node node) &#123; if (node.waitStatus == Node.CONDITION || node.prev == null) return false; if (node.next != null) // If has successor, it must be on queue return true; /* * node.prev can be non-null, but not yet on queue because * the CAS to place it on queue can fail. So we have to * traverse from tail to make sure it actually made it. It * will always be near the tail in calls to this method, and * unless the CAS failed (which is unlikely), it will be * there, so we hardly ever traverse much. */ return findNodeFromTail(node); &#125; /** * Returns true if node is on sync queue by searching backwards from tail. * Called only when needed by isOnSyncQueue. * @return true if present */ private boolean findNodeFromTail(Node node) &#123; Node t = tail; for (;;) &#123; if (t == node) return true; if (t == null) return false; t = t.prev; &#125; &#125; /** * Transfers a node from a condition queue onto sync queue. * Returns true if successful. * @param node the node * @return true if successfully transferred (else the node was * cancelled before signal) */ final boolean transferForSignal(Node node) &#123; /* * If cannot change waitStatus, the node has been cancelled. */ if (!compareAndSetWaitStatus(node, Node.CONDITION, 0)) return false; /* * Splice onto queue and try to set waitStatus of predecessor to * indicate that thread is (probably) waiting. If cancelled or * attempt to set waitStatus fails, wake up to resync (in which * case the waitStatus can be transiently and harmlessly wrong). */ Node p = enq(node); int ws = p.waitStatus; if (ws &gt; 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL)) LockSupport.unpark(node.thread); return true; &#125; /** * Transfers node, if necessary, to sync queue after a cancelled wait. * Returns true if thread was cancelled before being signalled. * * @param node the node * @return true if cancelled before the node was signalled */ final boolean transferAfterCancelledWait(Node node) &#123; if (compareAndSetWaitStatus(node, Node.CONDITION, 0)) &#123; enq(node); return true; &#125; /* * If we lost out to a signal(), then we can't proceed * until it finishes its enq(). Cancelling during an * incomplete transfer is both rare and transient, so just * spin. */ while (!isOnSyncQueue(node)) Thread.yield(); return false; &#125; /** * Invokes release with current state value; returns saved state. * Cancels node and throws exception on failure. * @param node the condition node for this wait * @return previous sync state */ final int fullyRelease(Node node) &#123; boolean failed = true; try &#123; int savedState = getState(); if (release(savedState)) &#123; failed = false; return savedState; &#125; else &#123; throw new IllegalMonitorStateException(); &#125; &#125; finally &#123; if (failed) node.waitStatus = Node.CANCELLED; &#125; &#125; // Instrumentation methods for conditions /** * Queries whether the given ConditionObject * uses this synchronizer as its lock. * * @param condition the condition * @return &#123;@code true&#125; if owned * @throws NullPointerException if the condition is null */ public final boolean owns(ConditionObject condition) &#123; return condition.isOwnedBy(this); &#125; /** * Queries whether any threads are waiting on the given condition * associated with this synchronizer. Note that because timeouts * and interrupts may occur at any time, a &#123;@code true&#125; return * does not guarantee that a future &#123;@code signal&#125; will awaken * any threads. This method is designed primarily for use in * monitoring of the system state. * * @param condition the condition * @return &#123;@code true&#125; if there are any waiting threads * @throws IllegalMonitorStateException if exclusive synchronization * is not held * @throws IllegalArgumentException if the given condition is * not associated with this synchronizer * @throws NullPointerException if the condition is null */ public final boolean hasWaiters(ConditionObject condition) &#123; if (!owns(condition)) throw new IllegalArgumentException("Not owner"); return condition.hasWaiters(); &#125; /** * Returns an estimate of the number of threads waiting on the * given condition associated with this synchronizer. Note that * because timeouts and interrupts may occur at any time, the * estimate serves only as an upper bound on the actual number of * waiters. This method is designed for use in monitoring of the * system state, not for synchronization control. * * @param condition the condition * @return the estimated number of waiting threads * @throws IllegalMonitorStateException if exclusive synchronization * is not held * @throws IllegalArgumentException if the given condition is * not associated with this synchronizer * @throws NullPointerException if the condition is null */ public final int getWaitQueueLength(ConditionObject condition) &#123; if (!owns(condition)) throw new IllegalArgumentException("Not owner"); return condition.getWaitQueueLength(); &#125; /** * Returns a collection containing those threads that may be * waiting on the given condition associated with this * synchronizer. Because the actual set of threads may change * dynamically while constructing this result, the returned * collection is only a best-effort estimate. The elements of the * returned collection are in no particular order. * * @param condition the condition * @return the collection of threads * @throws IllegalMonitorStateException if exclusive synchronization * is not held * @throws IllegalArgumentException if the given condition is * not associated with this synchronizer * @throws NullPointerException if the condition is null */ public final Collection&lt;Thread&gt; getWaitingThreads(ConditionObject condition) &#123; if (!owns(condition)) throw new IllegalArgumentException("Not owner"); return condition.getWaitingThreads(); &#125; /** * Condition implementation for a &#123;@link * AbstractQueuedSynchronizer&#125; serving as the basis of a &#123;@link * Lock&#125; implementation. * * &lt;p&gt;Method documentation for this class describes mechanics, * not behavioral specifications from the point of view of Lock * and Condition users. Exported versions of this class will in * general need to be accompanied by documentation describing * condition semantics that rely on those of the associated * &#123;@code AbstractQueuedSynchronizer&#125;. * * &lt;p&gt;This class is Serializable, but all fields are transient, * so deserialized conditions have no waiters. */ public class ConditionObject implements Condition, java.io.Serializable &#123; private static final long serialVersionUID = 1173984872572414699L; /** First node of condition queue. */ private transient Node firstWaiter; /** Last node of condition queue. */ private transient Node lastWaiter; /** * Creates a new &#123;@code ConditionObject&#125; instance. */ public ConditionObject() &#123; &#125; // Internal methods /** * Adds a new waiter to wait queue. * @return its new wait node */ private Node addConditionWaiter() &#123; Node t = lastWaiter; // If lastWaiter is cancelled, clean out. if (t != null &amp;&amp; t.waitStatus != Node.CONDITION) &#123; unlinkCancelledWaiters(); t = lastWaiter; &#125; Node node = new Node(Thread.currentThread(), Node.CONDITION); if (t == null) firstWaiter = node; else t.nextWaiter = node; lastWaiter = node; return node; &#125; /** * Removes and transfers nodes until hit non-cancelled one or * null. Split out from signal in part to encourage compilers * to inline the case of no waiters. * @param first (non-null) the first node on condition queue */ private void doSignal(Node first) &#123; do &#123; if ( (firstWaiter = first.nextWaiter) == null) lastWaiter = null; first.nextWaiter = null; &#125; while (!transferForSignal(first) &amp;&amp; (first = firstWaiter) != null); &#125; /** * Removes and transfers all nodes. * @param first (non-null) the first node on condition queue */ private void doSignalAll(Node first) &#123; lastWaiter = firstWaiter = null; do &#123; Node next = first.nextWaiter; first.nextWaiter = null; transferForSignal(first); first = next; &#125; while (first != null); &#125; /** * Unlinks cancelled waiter nodes from condition queue. * Called only while holding lock. This is called when * cancellation occurred during condition wait, and upon * insertion of a new waiter when lastWaiter is seen to have * been cancelled. This method is needed to avoid garbage * retention in the absence of signals. So even though it may * require a full traversal, it comes into play only when * timeouts or cancellations occur in the absence of * signals. It traverses all nodes rather than stopping at a * particular target to unlink all pointers to garbage nodes * without requiring many re-traversals during cancellation * storms. */ private void unlinkCancelledWaiters() &#123; Node t = firstWaiter; Node trail = null; while (t != null) &#123; Node next = t.nextWaiter; if (t.waitStatus != Node.CONDITION) &#123; t.nextWaiter = null; if (trail == null) firstWaiter = next; else trail.nextWaiter = next; if (next == null) lastWaiter = trail; &#125; else trail = t; t = next; &#125; &#125; // public methods /** * Moves the longest-waiting thread, if one exists, from the * wait queue for this condition to the wait queue for the * owning lock. * * @throws IllegalMonitorStateException if &#123;@link #isHeldExclusively&#125; * returns &#123;@code false&#125; */ public final void signal() &#123; if (!isHeldExclusively()) throw new IllegalMonitorStateException(); Node first = firstWaiter; if (first != null) doSignal(first); &#125; /** * Moves all threads from the wait queue for this condition to * the wait queue for the owning lock. * * @throws IllegalMonitorStateException if &#123;@link #isHeldExclusively&#125; * returns &#123;@code false&#125; */ public final void signalAll() &#123; if (!isHeldExclusively()) throw new IllegalMonitorStateException(); Node first = firstWaiter; if (first != null) doSignalAll(first); &#125; /** * Implements uninterruptible condition wait. * &lt;ol&gt; * &lt;li&gt; Save lock state returned by &#123;@link #getState&#125;. * &lt;li&gt; Invoke &#123;@link #release&#125; with saved state as argument, * throwing IllegalMonitorStateException if it fails. * &lt;li&gt; Block until signalled. * &lt;li&gt; Reacquire by invoking specialized version of * &#123;@link #acquire&#125; with saved state as argument. * &lt;/ol&gt; */ public final void awaitUninterruptibly() &#123; Node node = addConditionWaiter(); int savedState = fullyRelease(node); boolean interrupted = false; while (!isOnSyncQueue(node)) &#123; LockSupport.park(this); if (Thread.interrupted()) interrupted = true; &#125; if (acquireQueued(node, savedState) || interrupted) selfInterrupt(); &#125; /* * For interruptible waits, we need to track whether to throw * InterruptedException, if interrupted while blocked on * condition, versus reinterrupt current thread, if * interrupted while blocked waiting to re-acquire. */ /** Mode meaning to reinterrupt on exit from wait */ private static final int REINTERRUPT = 1; /** Mode meaning to throw InterruptedException on exit from wait */ private static final int THROW_IE = -1; /** * Checks for interrupt, returning THROW_IE if interrupted * before signalled, REINTERRUPT if after signalled, or * 0 if not interrupted. */ private int checkInterruptWhileWaiting(Node node) &#123; return Thread.interrupted() ? (transferAfterCancelledWait(node) ? THROW_IE : REINTERRUPT) : 0; &#125; /** * Throws InterruptedException, reinterrupts current thread, or * does nothing, depending on mode. */ private void reportInterruptAfterWait(int interruptMode) throws InterruptedException &#123; if (interruptMode == THROW_IE) throw new InterruptedException(); else if (interruptMode == REINTERRUPT) selfInterrupt(); &#125; /** * Implements interruptible condition wait. * &lt;ol&gt; * &lt;li&gt; If current thread is interrupted, throw InterruptedException. * &lt;li&gt; Save lock state returned by &#123;@link #getState&#125;. * &lt;li&gt; Invoke &#123;@link #release&#125; with saved state as argument, * throwing IllegalMonitorStateException if it fails. * &lt;li&gt; Block until signalled or interrupted. * &lt;li&gt; Reacquire by invoking specialized version of * &#123;@link #acquire&#125; with saved state as argument. * &lt;li&gt; If interrupted while blocked in step 4, throw InterruptedException. * &lt;/ol&gt; */ public final void await() throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); Node node = addConditionWaiter(); int savedState = fullyRelease(node); int interruptMode = 0; while (!isOnSyncQueue(node)) &#123; LockSupport.park(this); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; &#125; if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) // clean up if cancelled unlinkCancelledWaiters(); if (interruptMode != 0) reportInterruptAfterWait(interruptMode); &#125; /** * Implements timed condition wait. * &lt;ol&gt; * &lt;li&gt; If current thread is interrupted, throw InterruptedException. * &lt;li&gt; Save lock state returned by &#123;@link #getState&#125;. * &lt;li&gt; Invoke &#123;@link #release&#125; with saved state as argument, * throwing IllegalMonitorStateException if it fails. * &lt;li&gt; Block until signalled, interrupted, or timed out. * &lt;li&gt; Reacquire by invoking specialized version of * &#123;@link #acquire&#125; with saved state as argument. * &lt;li&gt; If interrupted while blocked in step 4, throw InterruptedException. * &lt;/ol&gt; */ public final long awaitNanos(long nanosTimeout) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); Node node = addConditionWaiter(); int savedState = fullyRelease(node); final long deadline = System.nanoTime() + nanosTimeout; int interruptMode = 0; while (!isOnSyncQueue(node)) &#123; if (nanosTimeout &lt;= 0L) &#123; transferAfterCancelledWait(node); break; &#125; if (nanosTimeout &gt;= spinForTimeoutThreshold) LockSupport.parkNanos(this, nanosTimeout); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; nanosTimeout = deadline - System.nanoTime(); &#125; if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) unlinkCancelledWaiters(); if (interruptMode != 0) reportInterruptAfterWait(interruptMode); return deadline - System.nanoTime(); &#125; /** * Implements absolute timed condition wait. * &lt;ol&gt; * &lt;li&gt; If current thread is interrupted, throw InterruptedException. * &lt;li&gt; Save lock state returned by &#123;@link #getState&#125;. * &lt;li&gt; Invoke &#123;@link #release&#125; with saved state as argument, * throwing IllegalMonitorStateException if it fails. * &lt;li&gt; Block until signalled, interrupted, or timed out. * &lt;li&gt; Reacquire by invoking specialized version of * &#123;@link #acquire&#125; with saved state as argument. * &lt;li&gt; If interrupted while blocked in step 4, throw InterruptedException. * &lt;li&gt; If timed out while blocked in step 4, return false, else true. * &lt;/ol&gt; */ public final boolean awaitUntil(Date deadline) throws InterruptedException &#123; long abstime = deadline.getTime(); if (Thread.interrupted()) throw new InterruptedException(); Node node = addConditionWaiter(); int savedState = fullyRelease(node); boolean timedout = false; int interruptMode = 0; while (!isOnSyncQueue(node)) &#123; if (System.currentTimeMillis() &gt; abstime) &#123; timedout = transferAfterCancelledWait(node); break; &#125; LockSupport.parkUntil(this, abstime); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; &#125; if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) unlinkCancelledWaiters(); if (interruptMode != 0) reportInterruptAfterWait(interruptMode); return !timedout; &#125; /** * Implements timed condition wait. * &lt;ol&gt; * &lt;li&gt; If current thread is interrupted, throw InterruptedException. * &lt;li&gt; Save lock state returned by &#123;@link #getState&#125;. * &lt;li&gt; Invoke &#123;@link #release&#125; with saved state as argument, * throwing IllegalMonitorStateException if it fails. * &lt;li&gt; Block until signalled, interrupted, or timed out. * &lt;li&gt; Reacquire by invoking specialized version of * &#123;@link #acquire&#125; with saved state as argument. * &lt;li&gt; If interrupted while blocked in step 4, throw InterruptedException. * &lt;li&gt; If timed out while blocked in step 4, return false, else true. * &lt;/ol&gt; */ public final boolean await(long time, TimeUnit unit) throws InterruptedException &#123; long nanosTimeout = unit.toNanos(time); if (Thread.interrupted()) throw new InterruptedException(); Node node = addConditionWaiter(); int savedState = fullyRelease(node); final long deadline = System.nanoTime() + nanosTimeout; boolean timedout = false; int interruptMode = 0; while (!isOnSyncQueue(node)) &#123; if (nanosTimeout &lt;= 0L) &#123; timedout = transferAfterCancelledWait(node); break; &#125; if (nanosTimeout &gt;= spinForTimeoutThreshold) LockSupport.parkNanos(this, nanosTimeout); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; nanosTimeout = deadline - System.nanoTime(); &#125; if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) unlinkCancelledWaiters(); if (interruptMode != 0) reportInterruptAfterWait(interruptMode); return !timedout; &#125; // support for instrumentation /** * Returns true if this condition was created by the given * synchronization object. * * @return &#123;@code true&#125; if owned */ final boolean isOwnedBy(AbstractQueuedSynchronizer sync) &#123; return sync == AbstractQueuedSynchronizer.this; &#125; /** * Queries whether any threads are waiting on this condition. * Implements &#123;@link AbstractQueuedSynchronizer#hasWaiters(ConditionObject)&#125;. * * @return &#123;@code true&#125; if there are any waiting threads * @throws IllegalMonitorStateException if &#123;@link #isHeldExclusively&#125; * returns &#123;@code false&#125; */ protected final boolean hasWaiters() &#123; if (!isHeldExclusively()) throw new IllegalMonitorStateException(); for (Node w = firstWaiter; w != null; w = w.nextWaiter) &#123; if (w.waitStatus == Node.CONDITION) return true; &#125; return false; &#125; /** * Returns an estimate of the number of threads waiting on * this condition. * Implements &#123;@link AbstractQueuedSynchronizer#getWaitQueueLength(ConditionObject)&#125;. * * @return the estimated number of waiting threads * @throws IllegalMonitorStateException if &#123;@link #isHeldExclusively&#125; * returns &#123;@code false&#125; */ protected final int getWaitQueueLength() &#123; if (!isHeldExclusively()) throw new IllegalMonitorStateException(); int n = 0; for (Node w = firstWaiter; w != null; w = w.nextWaiter) &#123; if (w.waitStatus == Node.CONDITION) ++n; &#125; return n; &#125; /** * Returns a collection containing those threads that may be * waiting on this Condition. * Implements &#123;@link AbstractQueuedSynchronizer#getWaitingThreads(ConditionObject)&#125;. * * @return the collection of threads * @throws IllegalMonitorStateException if &#123;@link #isHeldExclusively&#125; * returns &#123;@code false&#125; */ protected final Collection&lt;Thread&gt; getWaitingThreads() &#123; if (!isHeldExclusively()) throw new IllegalMonitorStateException(); ArrayList&lt;Thread&gt; list = new ArrayList&lt;Thread&gt;(); for (Node w = firstWaiter; w != null; w = w.nextWaiter) &#123; if (w.waitStatus == Node.CONDITION) &#123; Thread t = w.thread; if (t != null) list.add(t); &#125; &#125; return list; &#125; &#125; /** * Setup to support compareAndSet. We need to natively implement * this here: For the sake of permitting future enhancements, we * cannot explicitly subclass AtomicInteger, which would be * efficient and useful otherwise. So, as the lesser of evils, we * natively implement using hotspot intrinsics API. And while we * are at it, we do the same for other CASable fields (which could * otherwise be done with atomic field updaters). */ private static final Unsafe unsafe = Unsafe.getUnsafe(); private static final long stateOffset; private static final long headOffset; private static final long tailOffset; private static final long waitStatusOffset; private static final long nextOffset; static &#123; try &#123; stateOffset = unsafe.objectFieldOffset (AbstractQueuedSynchronizer.class.getDeclaredField("state")); headOffset = unsafe.objectFieldOffset (AbstractQueuedSynchronizer.class.getDeclaredField("head")); tailOffset = unsafe.objectFieldOffset (AbstractQueuedSynchronizer.class.getDeclaredField("tail")); waitStatusOffset = unsafe.objectFieldOffset (Node.class.getDeclaredField("waitStatus")); nextOffset = unsafe.objectFieldOffset (Node.class.getDeclaredField("next")); &#125; catch (Exception ex) &#123; throw new Error(ex); &#125; &#125; /** * CAS head field. Used only by enq. */ private final boolean compareAndSetHead(Node update) &#123; return unsafe.compareAndSwapObject(this, headOffset, null, update); &#125; /** * CAS tail field. Used only by enq. */ private final boolean compareAndSetTail(Node expect, Node update) &#123; return unsafe.compareAndSwapObject(this, tailOffset, expect, update); &#125; /** * CAS waitStatus field of a node. */ private static final boolean compareAndSetWaitStatus(Node node, int expect, int update) &#123; return unsafe.compareAndSwapInt(node, waitStatusOffset, expect, update); &#125; /** * CAS next field of a node. */ private static final boolean compareAndSetNext(Node node, Node expect, Node update) &#123; return unsafe.compareAndSwapObject(node, nextOffset, expect, update); &#125;&#125;]]></content>
  </entry>
  <entry>
    <title><![CDATA[爬虫框架设计]]></title>
    <url>%2F2017%2F03%2F02%2F%E7%88%AC%E8%99%AB%E6%A1%86%E6%9E%B6%E8%AE%BE%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[起源因为在公司做爬虫业务期间开发了一个新的基于Java的爬虫框架，故记录一下所思所想。 业务抽象一个好的技术框架最重要的任务是设计出合理的抽象模型，对于爬虫框架也是一样。 如何设计爬虫系统的抽象模型呢？先看一个典型的爬虫案例。 https://movie.douban.com/tag/喜剧 是一个电影列表页，我们的任务是遍历这个列表页，进入列表页中的电影详情页，并且抓取电影详情页中的电影数据。这样的一个任务，如果不用任何爬虫框架我们应该如何实现？ 思路应该是很明确的，我们用伪代码来表示： 12345678910111213141516List&lt;Movie&gt; items = new ArrayList()while (true) &#123; // 解析列表页 HTML html = getTagPage() List&lt;String&gt; movieDetailUrls = parseUrls(html) for (String url : movieDetailUrls) &#123; // 解析详情页 HTML detail = getMovieDetailHtml() Movie movie = parseMovieDetaiPage(detail) items.add(movie) &#125; // 如果有下一页，继续循环 if (!hasNextPage()) &#123; break &#125;&#125; 12345678910111213141516171819202122public DoubanTagSpider extends Spider &#123; // 配置名称, 起始URL等 ...... @Override public ParseResults parse(Response response) &#123; // 解析标签页 .... results.addRequest(new Request(tagPageUrl)); // 解析详情页 ..... results.addRequest(new Request(detailPageUrl, new CallBack(DoubanTagSpider :: parseDetail))); // 处理返回值 &#125; @override public ParseResults parseDetail(Response response) &#123; // 解析详情页 // 处理返回值 &#125;&#125; 1234567891011121314151617181920@Componentpublic class IMDBMovieCrawlTask &#123; @Crane("scratch.crawler.imdbTheatersMovieCrawlTask") public void crawlIMDBTheatersMovie() throws InitComponentException &#123; IMDBMovieSpider spider = new IMDBMovieSpider(); List&lt;String&gt; startUrls = Lists.newArrayList( "http://www.imdb.com/movies-in-theaters/"); spider.setStartUrls(startUrls); Settings settings = new Settings.Builder() .pipelineModuleFactory(PipelineFactory.class) .maxConcurrentCount(10) .maxRetryTimes(6) .needDupeFilter(false) .build(); Crawler crawler = new Crawler(spider, settings); crawler.start(); &#125;&#125; 1234567891011121314151617181920212223242526public class DoubanMovieSpider extends Spider &#123; ....... @Override public List&lt;Rule&gt; getRules() &#123; return Lists.newArrayList( // 电影详情页规则 new Rule(new LinkExtractor("https://movie.douban.com", "subject/\\d+/*")), // 标签页规则 new Rule(new LinkExtractor("https://movie.douban.com/tag/.*"), new CallBack("parseTag"), true) // 影人页规则 new Rule(new LinkExtractor("https://movie.douban.com", "celebrity/\\d+/*"), new CallBack("parseCelebrity"), true) ); &#125; // 解析电影详情页 public ParseResults parse(Response response) &#123;&#125; // 解析标签页 public ParseResults parseTag(Response response) &#123;&#125; // 解析影人详情页 public ParseResults parseCelebrity(Response response) &#123;&#125;&#125; 列表-详情页模式是一种非常常见的抓取模式，这个例子对设计爬虫系统的抽象模型有何启示呢？换言之，如果再去写另外一个列表-详情页模式的抓取，是否有一些可以复用的逻辑，不用二次开发了？ 答案是肯定的，总结一下有以下几点： 下载页面数据 异步化 失败自动重试 代理、cookie、userAgent等设置 URL调度 url去重 分布式 解析 自发现规则 方法回调 输出 我们对爬虫的流程进行分解之后，就会发现除了一些配置之外（代理，自发现规则等），只有解析是每个任务都避免不了的，而其余的都可以复用。这就是爬虫框架的意义所在。 架构图框架设计自然避免不了架构图，先贴一张架构图： 上面的图片是Scrapy的架构图，作为爬虫界最知名的爬虫框架，Scrapy的架构在我看来无疑是最棒的。所以，没有必要在这块重复造轮子，照搬就是。 解释一下图中的几个重要模块： Downloader：下载器，负责下载页面内容，处理代理，cookie等设置； Spider：解析器，负责解析页面内容，输入是HTML的response，输出是结构化的Items； Scheduler：调度器，负责调度待抓取的URL以及URL去重； Item Pipelines：负责处理结构化的Items数据； Engine：引擎，负责将上面的这几个部分连接起来一起工作； 除此之外，还有几个重要类没有体现在架构图中： Settings：爬虫任务配置，任何配置都只会在Settings里配置； Crawler：每个爬虫任务都对应一个Crawler 为什么要开发新的爬虫框架按理说Scrapy已经是很不错的爬虫框架了，那么为什么又要重新开发一个呢？原因有以下几个： Scrapy不支持分布式爬虫； 公司的后端环境是Java环境，用Python会带来很多的兼容问题； Java届最有名的爬虫框架WebMagic提供的爬虫模型不够好； 爬虫框架这个轮子并不难造，并且如果是自己造的，二次扩展显然更加简便； WebMagic的问题(不了解WebMagic的同学可以忽略)先上一张架构图 PageProcessor定义混乱PageProcessor，顾名思义，是处理页面解析内容的，对应到Scrapy中的Spider。但是，它还有两个其它的任务：1. 配置site，例如编码、抓取间隔、重试次数等；2. 启动整个爬虫任务。举个例子： 1234567891011121314151617181920public class DoubanMovieDetailPageProcessor implements PageProcessor &#123; // 配置site信息 private Site site = Site.me().setRetryTimes(3).setSleepTime(1000); @Override public void process(Page page) &#123; 抽取页面逻辑 &#125; // getSite方法很多余 @Override public Site getSite() &#123; return site; &#125; public static void main(String[] args) &#123; 通过Spider类启动爬虫任务 &#125;&#125; 很明显，无论是配置Site信息，还是启动爬虫任务都不是PageProcessor的职责。在Scrapy中，配置Site信息有Settings设置，启动爬虫任务有Crawler类，而Scrapy中的PageProcessor，也就是Spider类，只处理页面抽取，这样做逻辑要通顺很多。 Page类中不应该有ResultItemsResultItems是抽取页面数据后产生的结构化数据，而Page对象是下载后的页面对象，Page类中有个ResultItems没有道理。应当和Scrapy一样，ResultItems是process方法的返回值，然后交给Pipeline处理。 多页面关联解析问题类似列表页-详情页这种模式的抓取任务，我们需要解析两个页面，列表页和详情页，用WebMagic怎么实现呢？ 12345678910111213@overridepublic void process(Page page) &#123; if (page.getUrl().regex(URL_LIST).match()) &#123; page.addTargetRequests(page.getHtml().xpath("//div[@class=\"articleList\"]").links().regex(URL_POST).all()); page.addTargetRequests(page.getHtml().links().regex(URL_LIST).all()); //文章页 &#125; else &#123; page.putField("title", page.getHtml().xpath("//div[@class='articalTitle']/h2")); page.putField("content", page.getHtml().xpath("//div[@id='articlebody']//div[@class='articalContent']")); page.putField("date", page.getHtml().xpath("//div[@id='articlebody']//span[@class='time SG_txtc']").regex("\\((.*)\\)")); &#125;&#125; 在Scrapy中是如何实现的？ 123456789101112def parse(self, response): urls = response.xpath('//div[contains(@class, "open-pt")]//a/@href').extract() for url in urls: yield scrapy.Request(url, dont_filter = True, callback = self.parse_star)def parse_star(self, response): schedule_url = response.xpath(u'//a[contains(@title, "全部行程")]/@href').extract_first() for month in xrange(1, 2): yield scrapy.Request('%s2016/%d/#blanking' %(schedule_url, month), callback = self.parse_star_schedule)def parse_star_schedule(self, response): 解析行程页内容 Scrapy每一个页面都对应了一个解析方法，而WebMagic则是一个Else if的判断，Scrapy明显更优。 配置自发现的规则不够直接在PageProcessor中配置自发现的规则是这么写的： 1page.addTargetRequests(page.getHtml().links().regex("(https://github\\.com/\\w+/\\w+)").all()); 和Scrapy相比，高下立判: 1234rules = ( Rule(LinkExtractor(allow=('category\.php', ), deny=('subsection\.php', ))), Rule(LinkExtractor(allow=('item\.php', )), callback='parse_item'),) 配置这种规则并不是PageProcessor的职责，而是Site的职责，放在PageProcessor中明显不合理。 并发下载问题这是一个经典问题，在此不多说了，下载是一个IO时间远大于CPU时间的场景，用IO多路复用更合适，而不是多线程模型。 WebMagic的优点说了这么多缺点，WebMagic还是有优点的。 上手很快，文档比较全 Downloader，Scheduler，Pipeline很容易扩展 代码结构比较清晰 开发爬虫框架时的几个难题前面也提到了，Scrapy作为业界最佳爬虫框架，大的方面比如架构照搬就好了。但是毕竟语言有差异，很多实现细节是不能用相似方案实现的，下面主要讲几个开发爬虫框架时碰到的问题。 动态初始化组件Downloader、Scheduler和Pipeline的实现类可以由使用方替换，所以需要在爬虫任务启动时动态生成。我们希望使用方通过配置类名的方式告知实现类，而不是new出来对象再传递给Engine。这样Engine也更加容易管理各个组件，避免对象逸出。 12345Engine(Settings settings) throws InitComponentException &#123; this.downloader = DownloaderCreator.createDownloader(settings); this.scheduler = SchedulerCreator.createScheduler(settings); this.pipeline = PipelineCreator.createPipeline(settings);&#125; 以DownloaderCreateor为例来说明初始化过程。 1234567891011121314151617public static Downloader createDownloader(Settings settings) throws InitComponentException &#123; try &#123; // 通过配置DownloaderModuleFactory自定义下载器 DownloaderFactory factory = (DownloaderFactory) Class.forName( settings.getDownloaderModuleFactory()).newInstance(); return factory.createDownloader(settings); &#125; catch (Exception e) &#123; throw new InitComponentException(e); &#125;&#125;interface DownloaderFactory &#123; // 通过settings参数定义Downloader Downloader createDownloader(Settings settings);&#125;public class CustomizeDownloader implements Downloader &#123;&#125; 自定义下载器需要实现DownloaderFactory和CustomizedDownloader。 注意一下，这里用到了工厂方法模式，Downloader的实现和Settings解耦，在DownloaderFactory中完成Downloader的具体实现代码。 异步化下载&amp;限速&amp;终止条件这三个问题都是Engine类需要解决的核心问题。 代码1234567891011121314151617181920private void startSchedule() &#123; LOGGER.info("&#123;&#125; begin to schedule !", spider.getSpiderName()); while (true) &#123; if (needBackout()) &#123; waitOneSecond(); continue; &#125; Request request = scheduler.poll(); if (request != null) &#123; LOGGER.debug("&#123;&#125; request = &#123;&#125;", spider.getSpiderName(), request.getUrl()); downloaderMiddlewareManager.processRequest(request); &#125; else if (!isSpiderIdle()) &#123; waitOneSecond(); &#125; else if (scheduler.isEmpty()) &#123; LOGGER.info("&#123;&#125; stop", spider.getSpiderName()); break; &#125; &#125;&#125; 异步化下载为了保证抓取效率，下载器必须并行下载多个页面。 和经典的Web服务器并发模型类似，主要有两种方式：1.单线程异步下载，回调处理页面数据的方法；2.多线程同步下载。 因为下载是个重IO操作，CPU操作很少，使用线程池的话，大多数时间线程都是在等待，采用多路IO复用这种方式明显是更为合适的。但是，因为下载操作需要downloader支持，所以具体实现还得看downloader是如何做的。比如我们需要使用公司提供的FetchServer，它只能利用线程池的方式来提供异步化，那么我们也只能用线程池这种方式了。 从上面的代码中，downloaderMiddlewareManager.processRequest(request);是个异步操作，不会等待方法返回才继续执行。 限速下载是异步的，但是不能不限速，倘若抓取速度太快是很容易被封禁的。在我们的框架中，限速有两种方式：1. scheduler限制url流出速度，2. downloader限制同时下载数。这两种方式从两个维度去限速，都可以通过settings来设置。 上面的代码中有两个方法，needTimeout和isSpiderIdle，我们先来看这两个方法的实现： 12345678private boolean needTimeout() &#123; return needTimeout();&#125;// downloader.needTimeoutpublic boolean needTimeout() &#123; return activeCount.intValue() &gt; maxConcurrentCount;&#125; 因为我们会设置downloader的同时最大下载数，到达最大下载数时需要暂停，这里可以看到核心是：activeCount.intValue() &gt; maxConcurrentCount;如果这句执行为true就需要暂停一下，等待activeCount值小于maxConcurrentCount后再继续执行。 另外，scheduler.poll();会根据setting中的设置定期吐出URL，而不是调用poll就会立即返回。 这两种限速方式不必同时发挥作用，只需要根据自己的需要按需定制。 终止条件终止条件是什么呢？当最后一个URL下载完成且没有产生下一个URL时，爬虫任务就可以结束了。 我们来看一下isSpideridle方法的实现： 1234567private boolean isSpiderIdle() &#123; return !downloader.isActive();&#125;public boolean isActive() &#123; return activeCount.intValue() &gt; 0;&#125; 我们会在downloader中进行计数，只有activeCount也就是下载任务为0时，downloader才是idle的。这里需要提一下，因为我们的下载器是异步的，只有下载完成并且完成回调，activeCount才会减一。 在判断终止条件时，需要先判断downloader是否idle，然后判断scheduler是否empty。倘若反过来，则有可能提前终止爬虫任务。 Spider根据不同URL调用对应的解析方法在上述多页面关联解析问题中，我们看到了Scrapy是如何解决多页面关联问题的。那么在Java中，我们应该怎么实现这种根据不同URL调用对应解析方法的呢？ 先来看一下如何使用： 123456public ParseResults parse(Response response) &#123; ParseResults results = new ParseResults(); // parse code Request request = new Request(url, callback); return results;&#125; Engine会解析parseResults，对于items会丢给pipeline去处理，对于request会丢给scheduler。注意到request的构造方法中有个callback，当Engine处理到这个request时，当页面下载完成后，Engine会调用这个request中的callback方法来解析页面内容。这样就实现了和Scrapy类似的功能。 我们借助Java8的Consumer类来实现，如果request没有定义callback，则调用默认解析方法parse来解析，具体实现： 123456789101112131415161718192021222324252627ParseResults parseResponse(Response response) throws ParseException &#123; ParseResults results = new ParseResults(); // apply spider rules results.addRequests(applyRules(response)); ParseResults spiderResults; Request request = response.getRequest(); try &#123; // 调用具体的解析方法 spiderResults = invokeCallBack(request, response); &#125; catch (Exception e) &#123; throw new ParseException(e); &#125; if (spiderResults != null) &#123; results.addItems(spiderResults.getItems()); results.addRequests(spiderResults.getRequests()); &#125; return results;&#125;private ParseResults invokeCallBack(Request request, Response response) throws IllegalAccessException, NoSuchMethodException, InvocationTargetException &#123; if (request.getCallBack() == null) &#123; request.setCallBack(this :: parse); &#125; return request.getCallBack().apply(response);&#125; 选择器实现选择器选用了JSoup和Xsoup，使用和Scrapy的类似，不再赘述。 分布式爬虫Scrapy是单机式爬虫框架，有较大的爬虫任务时会遇到性能瓶颈，分布式爬虫因运而生。分布式爬虫和单机式爬虫有什么区别呢？有以下几个： 共享待抓取URL队列 共享URL去重 抓取结果合并 支持新的机器加入，并且机器宕机不影响任务继续进行 根据上面的区别可以看出，核心点就是分布式的URL队列。基于Scrapy的分布式爬虫有Scrapy-redis，利用了redis来存储待抓取的URL队列，实现了分布式的爬虫。 在本框架中我们同样借助redis实现了RedisScheduler。如果爬虫任务想实现分布式抓取，可以在任务配置时把schduler配置为RedisScheduler即可。 取得的成效目前利用本框架实现的爬虫任务已经有14个，相比较于之前没有爬虫框架的时候，开发新的爬虫任务能减少将近50%的代码量，大大提升了开发效率。]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java泛型]]></title>
    <url>%2F2017%2F03%2F01%2FJava%E6%B3%9B%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[泛型是什么最明显的例子是容器类，容器类需要为各种各样的类服务。倘若使用Object类来构建容器类，那么很容易出现类型转换的问题。泛型提供了强制类型的方法。 泛型怎么用类型参数用作占位符，在运行时为类分配类型。根据需要，可能有一个或多个类型参数，并且可以用于整个类。根据惯例，类型参数是单个大写字母，该字母用于指示所定义的参数类型。下面列出每个用例的标准类型参数： E：元素 K：键 N：数字 T：类型 V：值 S、U、V 等：多参数情况中的第 2、3、4 个类型 有界类型我们经常会遇到这种情况，需要指定泛型类型，但希望控制可以指定的类型，而非不加限制。有界类型 在类型参数部分指定 extends 或 super 关键字，分别用上限或下限限制类型，从而限制泛型类型的边界。例如： &lt;T extends UpperBoundType&gt; 泛型方法有时，我们可能不知道传入方法的参数类型。在方法级别应用泛型可以解决此类问题。方法参数可以包含泛型类型，方法也可以包含泛型返回类型。12345public static &lt;N extends Number&gt; double add(N a, N b)&#123; double sum = 0; sum = a.doubleValue() + b.doubleValue(); return sum;&#125; 通配符某些情况下，编写指定未知类型的代码很有用。问号 (?) 通配符可用于使用泛型代码表示未知类型。通配符可用于参数、字段、局部变量和返回类型。但最好不要在返回类型中使用通配符，因为确切知道方法返回的类型更安全。123456789101112131415public static &lt;T&gt; void checkList(List&lt;?&gt; myList, T obj)&#123; if(myList.contains(obj))&#123; System.out.println("The list contains the element: " + obj); &#125; else &#123; System.out.println("The list does not contain the element: " + obj); &#125;&#125;public static &lt;T&gt; void checkNumber(List&lt;? extends Number&gt; myList, T obj)&#123; if(myList.contains(obj))&#123; System.out.println("The list " + myList + " contains the element: " + obj); &#125; else &#123; System.out.println("The list " + myList + " does not contain the element: " + obj); &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>泛型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[日志文件系统]]></title>
    <url>%2F2017%2F02%2F26%2F%E6%97%A5%E5%BF%97%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[核心问题崩溃一致性问题 写文件的几个步骤 写inode 写bitmap 写data block 不一致现象上面的三个步骤，可能只有某一个成功，或者某两个成功都会导致一些不一致的问题 日志（write-ahead logging）Linux ext3 and ext4用的就是这种方式 基本理论当要更新磁盘数据时，我们先记录一点日志，说明我们要做的事情，于是叫做写前日志。保证写前日志成功后再开设写操作，就能够在出问题的时候进行恢复。 基本流程 Txb包含transaction identifier (TID). TxE是事务结束的标志，也包含TID 当写日志成功后，开始真正的写文件内容 问题相比于依次写I[v2]，B[v2]和Db，并行写肯定更快，但是可能会导致数据不一致 优化方法 先写TxB，metadata和data，等成功后，再写TxE 在内存中合并写，之后再写到磁盘 日志容量问题 增加super block，记录空间使用情况，如果某个Tx已经完成任务就可以在super block中进行标记 Db写两次问题日志是只记录metadata，事务开始时就把Db写入到它应该在的位置 最终步骤 写数据：将数据写入到最终位置，等待完成 将元数据写入日志：把TxB和metadata写入日志，等待完成 日志提交：把包含TxE的事务提交block写入日志，等待完成 提交元数据：将元数据写入到它们的最终位置 释放：在super block中记录该事务的空间可以被释放 时间线]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>存储</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kafka文件存储]]></title>
    <url>%2F2017%2F02%2F23%2Fkafka%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%2F</url>
    <content type="text"><![CDATA[Kafka文件存储机制那些事 每个topic的partition会分散成segment来存储，每个segment是固定大小，大概500M segment的存储分为索引文件和内容文件，分别为index文件和log文件，有意思的是index文件名包含了消息条数的信息 上述图中索引文件存储大量元数据，数据文件存储大量消息，索引文件中元数据指向对应数据文件中message的物理偏移地址。其中以索引文件中元数据3,497为例，依次在数据文件中表示第3个message(在全局partiton表示第368772个message)、以及该消息的物理偏移地址为497。 从上述图了解到segment data file由许多message组成，下面详细说明message物理结构如下： 在partition中如何通过offset查找message 第一步查找segment file上述图2为例，其中00000000000000000000.index表示最开始的文件，起始偏移量(offset)为0.第二个文件00000000000000368769.index的消息量起始偏移量为368770 = 368769 + 1.同样，第三个文件00000000000000737337.index的起始偏移量为737338=737337 + 1，其他后续文件依次类推，以起始偏移量命名并排序这些文件，只要根据offset 二分查找文件列表，就可以快速定位到具体文件。当offset=368776时定位到00000000000000368769.index | log 第二步通过segment file查找message通过第一步定位到segment file，当offset=368776时，依次定位到00000000000000368769.index的元数据物理位置和00000000000000368769.log的物理偏移地址，然后再通过00000000000000368769.log顺序查找直到offset=368776为止。 总结Kafka高效文件存储设计特点 Kafka把topic中一个parition大文件分成多个小文件段，通过多个小文件段，就容易定期清除或删除已经消费完文件，减少磁盘占用。 通过索引信息可以快速定位message和确定response的最大大小。 通过index元数据全部映射到memory，可以避免segment file的IO磁盘操作。 通过索引文件稀疏存储，可以大幅降低index文件元数据占用空间大小。]]></content>
      <tags>
        <tag>存储</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用的命令]]></title>
    <url>%2F2017%2F02%2F23%2F%E5%B8%B8%E7%94%A8%E7%9A%84%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[sed替换：sed -i “” ‘s/..\/images/\/images/g’ *.md git git init git add –all git commit -m “Initial Commit” git remote add origin git@github.com:xurongyang/xurongyang.github.io.git git push origin master awk ‘{sum+=$2} (NR&gt;=100){exit}END{print sum}’ search_keyword_0313.txt]]></content>
  </entry>
  <entry>
    <title><![CDATA[零拷贝]]></title>
    <url>%2F2017%2F02%2F23%2F%E9%9B%B6%E6%8B%B7%E8%B4%9D%2F</url>
    <content type="text"><![CDATA[Efficient data transfer through zero copy]]></content>
  </entry>
  <entry>
    <title><![CDATA[Selector总结]]></title>
    <url>%2F2017%2F02%2F22%2FSelector%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[SelectorSelectableChannel的多路开关选择器，其select方法对应于epoll，select，kqueue SelectionKey一个绑定了某个selector的可被选择的channel对象的包装（a selectable channel’s registration with a selector is represented by a SelectionKey object.A selection key is created each time a channel is registered with a selector)。 SelectionKey是线程安全的。 一个selector有三个selectionKey的Set集合。 key集合代表当前已注册的管道，通过keys方法获得。 selectedKey集合代表在上次selection操作时已经被检测到准备好进行下一步的动作（The selected-key set is the set of keys such that each key’s channel was detected to be ready for at least one of the operations identified in the key’s interest set during a prior selection operation)，通过selectedKeys方法获得，selectedKeys是keySet的子集。 cancelledKey集合是已经取消但是没有删除的管道对象集合（have been cancelled but whose channels have not yet been deregistered） 所有的三个集合在一个新的selector中都是空的。 Selection操作 清空cancelledKey集合 咨询操作系统每一个channel当前的状态，是否已经ready。 If the channel’s key is not already in the selected-key set then it is added to that set and its ready-operation set is modified to identify exactly those operations for which the channel is now reported to be ready. Any readiness information previously recorded in the ready set is discarded. Otherwise the channel’s key is already in the selected-key set, so its ready-operation set is modified to identify any new operations for which the channel is reported to be ready. Any readiness information previously recorded in the ready set is preserved; in other words, the ready set returned by the underlying system is bitwise-disjoined into the key’s current ready set. 如果在步骤 (2) 的执行过程中要将任意键添加到已取消键集中，则处理过程如步骤 (1) select(), select(long), selectNow() 三个方法的区别在于是否等待一个或多个channel的状态变为ready，以及多久。 并发Selectors是线程安全的，但是keySet不是。 在selection的操作中对selectionKey的修改没有影响，在下次selection才会提现出来。 SelectableChannelSelectableChannel通过registe方法和一个selector对象绑定，register方法返回selectionKey对象来代表channel的注册。 A channel cannot be deregistered directly; instead, the key representing its registration must be cancelled. 一个channel只能和一个selector注册上。SelectableChannel是线程安全的。 在JAVA NIO中的三个核心的组件：Channels、Buffers和Selectors]]></content>
  </entry>
  <entry>
    <title><![CDATA[摘抄]]></title>
    <url>%2F2017%2F02%2F22%2F%E6%91%98%E6%8A%84%2F</url>
    <content type="text"><![CDATA[阿里CTO行癫西雅图首次披露阿里技术布局 “不论是人工智能还是其他前沿技术，都离不开高质量的数据、强大的计算平台和高效的算法平台。”阿里巴巴集团CTO张建锋在西雅图表示，“只有这三件事放在一起，才能真正在机器学习和人工智能领域取得突破。”]]></content>
  </entry>
  <entry>
    <title><![CDATA[日志解读]]></title>
    <url>%2F2017%2F02%2F21%2F%E6%97%A5%E5%BF%97%E8%A7%A3%E8%AF%BB%2F</url>
    <content type="text"><![CDATA[The Log: What every software engineer should know about real-time data’s unifying abstraction学习笔记：The Log（我所读过的最好的一篇分布式技术文章) 日志解耦了时间和任一特定的物理时钟（physical clock），日志有一个好处是顺序写效率较高 日志解决了两个问题：更改动作的排序和数据的分发。这两个问题在分布式数据系统中更是尤为重要。协商达成一致的更改动作的顺序（或是协商达成不一致做法并去做有副作用的数据拷贝）是分布式系统设计的核心问题之一。 状态机复制如果两个相同的、确定性的进程从同一状态开始，并且以相同的顺序获得相同的输入，那么这两个进程将会生成相同的输出，并且结束在相同的状态。 进程状态 是进程保存在机器上的任何数据，在进程处理结束的时候，这些数据要么保存在内存里，要么保存在磁盘上。 为了让讨论更具体些，我们考虑一个简单的案例，有一个数据库和一组缓存服务器集群。 日志提供了一个方法可以同步更新到所有这些系统，并推断出每个系统的所处在的时间点。 我们假设做了一个写操作，对应日志记录X，然后要从缓存做一次读操作。 如果我们想保证看到的不是过时的数据，我们只需保证，不要去读取那些复制操作还没有跟上X的缓存即可。 之前考虑过做数据库读写分离的问题在于主从延迟导致的读取不到最新数据的问题可以用这种方式解决。 为了进一步理解这一优势，设想一个简单的场景 —— 显示在工作职位页面提交的职位信息。 职位页面应当只包括显示职位所需的逻辑。 然而，在足够动态站点中，这很容易就变成与职位显示无关的额外逻辑的点缀。 例如，我们将对如下的系统进行集成： 发送数据到Hadoop和数据仓库中，以做离线数据处理 浏览计数，确保查看者不是一个内容爬虫 聚合浏览信息，在职位提交者的分析页面显示记录浏览信息，确保合适地设置了用户的推荐职位的展示上限（不想重复地展示同样内容给用户） 推荐系统可能需要记录浏览，以正确的跟踪职位的流行程度 等等用不了多久，简单的职位显示变得相当的复杂。 与此同时，还要增加职位显示的其它终端 —— 移动终端应用等等 —— 这样的逻辑必须继续实现，复杂程度被不断地提升。 更糟的是，我们需要交互的系统是多方需求交织缠绕在一起的 —— 负责显示职位的工程师需要知道多个其它系统和功能，才可以确保集成的正确。 这里仅是简单描述了问题，实际应用系统只会更加复杂。 『事件驱动』风格提供了简化这类问题的方案。 职位显示页面现在只负责显示职位并记录显示职位的信息，如职位相关属性、页面浏览者及其它有价值的信息。 其它所有关心这个信息的系统诸如推荐系统、安全系统、职位提交分析系统和数据仓库，只需订阅上面的输出数据进行各自的处理。 显示代码并不需要关注其它的系统，也不需要因为增加了数据的消费者而做改变。 A Log-centric Infrastructure Stack]]></content>
  </entry>
  <entry>
    <title><![CDATA[Java锁实现]]></title>
    <url>%2F2017%2F02%2F21%2FJava%E9%94%81%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AtomicReference和volatile的区别]]></title>
    <url>%2F2017%2F02%2F17%2FAtomicReference%E5%92%8Cvolatile%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[AtomicReference中引用的变量是volatile，get和set方法跟volatile一样，只不过提供了compareAndSet]]></content>
  </entry>
  <entry>
    <title><![CDATA[Java内存模型]]></title>
    <url>%2F2017%2F02%2F14%2FJava%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[内存模型到底是啥（模型即抽象）为什么需要内存模型（性能、并发）各种语言的内存模型（C++、C）Java内存模型的特点（JMM、虚拟机）内存模型的根源典型硬件模型（NUMA、多核、非共享Cache）MESI协议内存屏障Java内存模型Happens-before规则synchronized、volatile和lock并发三大特性解惑原子性（如何实现、CXMP）可见性（对谁可见）有序性起源最早接触到Java内存模型这个概念的源于深入理解Java内存模型系列文章，第一次并没有看懂，有很多的概念理解不了，后来有了更多的经验积累，对Java内存模型的认识也逐渐深刻，故有此篇文章。 定义先来解释一下Java内存模型，Java内存模型是 定义Java内存模型规范了Java虚拟机与计算机内存是如何协同工作的。Java虚拟机是一个完整的计算机的一个模型，因此这个模型自然也包含一个内存模型——又称为Java内存模型。 Java内存模型规定了如何和何时可以看到由其他线程修改过后的共享变量的值，以及在必须时如何同步的访问共享变量。 参考 Java内存模型 源码剖析AQS在几个同步工具类中的使用]]></content>
      <categories>
        <category>Java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Operating-Systems读书笔记-Persistence]]></title>
    <url>%2F2017%2F02%2F09%2FOperating-Systems%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-Persistence%2F</url>
    <content type="text"><![CDATA[PersistenceI/O设备 HOW TO INTEGRATE I/O INTO SYSTEMS 设备抽象 status register, which can be read to see the current statusof the device. command register, to tell the device to perform a certaintask. a data register to pass data to the device, or get data fromthe device. 设备协议While (STATUS == BUSY) ; // wait until device is not busy Write data to DATA register Write command to COMMAND register (Doing so starts the device and executes the command) While (STATUS == BUSY) ; // wait until device is done with your request Device Driver HOW TO BUILD A DEVICE-NEUTRAL OS 硬盘一个扇区的写是原子的 Disk Scheduling SSTF: Shortest Seek Time First Elevator (a.k.a. SCAN or C-SCAN) SPTF: Shortest Positioning Time First 文件系统实现 HOW TO IMPLEMENT A SIMPLE FILE SYSTEM data structure and access methods(open, read, write, close) 整体结构superBlock包含了该文件系统包含多少个inode和多少个data block，当mount文件系统时，操作系统会首先读取superBlock，然后将该卷连接到文件系统上。 Inode每个Inode都有一个唯一的inumber对应，当给定一个inumber时，就能够计算出来inode在磁盘上的位置。 blk = (inumber * sizeof(inode_t)) / blockSize; sector = ((blk * blockSize) + inodeStartAddr) / sectorSize; 读写过程 The Multi-Level IndexInode节点中的block字段包含了该文件所有block的地址，为了支持更大的文件，采用了多级结构。 Directory Organization目录中的内容是一个Pair&lt;entryName，inode number&gt;的列表 Cache虚拟内容和文件系统使用的缓存是动态决定的。写文件的时候不会直接写磁盘，会在内容中进行缓存（5s~30s）。这样能获得更好的效率，但是存在丢数据的情况。可以使用fsync()强制写磁盘。 性能优化 HOW TO ORGANIZE ON-DISK DATA TO IMPROVE PERFORMANCE 磁盘硬件结构， 日志式 HOW TO UPDATE THE DISK DESPITE CRASHESJournaling Data write: Write data to final location; wait for completion(the wait is optional; see below for details). Journal metadata write: Write the begin block and metadata to the log; wait for writes to complete. Journal commit: Write the transaction commit block (containing TxE) to the log; wait for the write to complete; the transaction (including data) is now committed. Checkpoint metadata: Write the contents of the metadata update to their final locations within the file system. Free: Later, mark the transaction free in journal superblock.]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Operating Systems读书笔记(Concurrency)]]></title>
    <url>%2F2017%2F02%2F07%2FOperating-Systems%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-Concurrency%2F</url>
    <content type="text"><![CDATA[锁 HOW TO BUILD A LOCK 要创建一个可用的锁，我们既需要硬件的帮助，也需要操作系统的帮助。 Concurrency这部分讲得太浅，不写了。]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[计算机系统]]></title>
    <url>%2F2017%2F01%2F29%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[从08年进入大学开始学习计算机，到如今居然已经有了大约10年，回想起来，对一个程序在计算机上的运行还是不够清楚，实在令人惭愧。这是促使我去完整了解计算机系统的动力，也是对知识框架的良好补充。 计算机的本质计算机的本质，我认为，是能够以任何逻辑处理任何信息，两个关键点，1.可编程，逻辑可以由用户自定义，没有任何非逻辑上的限制。2.计算机处理的是信息，而且是任意的信息。计算其实就等同于逻辑处理（布尔代数）。 大多数的电子设备和计算机的区别在于他们能处理信息，比如通过按钮输入，但是，基本不支持编程。 信息的定义毫无疑问，自然语言可以承当信息的载体。对于计算机要能处理信息，自然需要理解信息。对于人来讲，我们使用自然语言来传递信息，本质上是建立起自然语言与物理世界的对应关系。好比如提到飞机，脑海中就能浮现出飞机的模样。我们能有这样的本事是因为我们拥有大脑。但是计算机怎么做呢？ 自然语言物理世界，这是我们大脑的工作方式。倘若我们建立起某种其它方式和自然语言的对应关系，那么这种方式就可以用来承载信息。 《编码》这本书花了很大的篇幅来讲各种各样的编码。布莱叶盲文建立起矩形点阵与英文字母之间的对应关系，如此盲人就可以识别文字。莫斯码利用各种各样的点和短线来定义英文字母，也能够用来传递信息。所以，不光自然语言，这个世界已经存在了各种各样编码来传递信息。计算机用的是二进制来表示信息。为什么是二进制？ 二进制表示起来最简单，0和1用一个开关就可以表示，而且二进制和任意进制本质上是一致的。 逻辑的数学表示布尔代数 计算机是如何工作的Computer Systems: A Programmer’s Perspective就是来讲这个主题的，但是一不够底层，二有点杂，三呢，用自己的语言描述一遍显然更加记得更加牢靠。]]></content>
  </entry>
  <entry>
    <title><![CDATA[两种处理器内存模型]]></title>
    <url>%2F2017%2F01%2F23%2F%E4%B8%A4%E7%A7%8D%E5%A4%84%E7%90%86%E5%99%A8%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[Coherent Cache Machine NUMA]]></content>
  </entry>
  <entry>
    <title><![CDATA[SpinLock实现]]></title>
    <url>%2F2017%2F01%2F17%2FSpinLock%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[From: http://coderbee.net/index.php/concurrent/20131115/577 SpinLock实现自旋锁适用于锁保护的临界区很小的情况，临界区很小的话，锁占用的时间就很短。 import java.util.concurrent.atomic.AtomicReference; public class SpinLock { private AtomicReference&lt;Thread&gt; owner = new AtomicReference&lt;Thread&gt;(); public void lock() { Thread currentThread = Thread.currentThread(); // 如果锁未被占用，则设置当前线程为锁的拥有者 while (!owner.compareAndSet(null, currentThread)) { } } public void unlock() { Thread currentThread = Thread.currentThread(); // 只有锁的拥有者才能释放锁 owner.compareAndSet(currentThread, null); } } 缺点： CAS操作需要硬件的配合； 保证各个CPU的缓存（L1、L2、L3、跨CPU Socket、主存）的数据一致性，通讯开销很大，在多处理器系统上更严重； 没法保证公平性，不保证等待进程/线程按照FIFO顺序获得锁。 Ticket LockTicket Lock 是为了解决上面的公平性问题，类似于现实中银行柜台的排队叫号：锁拥有一个服务号，表示正在服务的线程，还有一个排队号；每个线程尝试获取锁之前先拿一个排队号，然后不断轮询锁的当前服务号是否是自己的排队号，如果是，则表示自己拥有了锁，不是则继续轮询。 当线程释放锁时，将服务号加1，这样下一个线程看到这个变化，就退出自旋。 import java.util.concurrent.atomic.AtomicInteger; public class TicketLock { private AtomicInteger serviceNum = new AtomicInteger(); // 服务号 private AtomicInteger ticketNum = new AtomicInteger(); // 排队号 public int lock() { // 首先原子性地获得一个排队号 int myTicketNum = ticketNum.getAndIncrement(); // 只要当前服务号不是自己的就不断轮询 while (serviceNum.get() != myTicketNum) { } return myTicketNum; } public void unlock(int myTicket) { // 只有当前线程拥有者才能释放锁 int next = myTicket + 1; serviceNum.compareAndSet(myTicket, next); } } 缺点： Ticket Lock 虽然解决了公平性的问题，但是多处理器系统上，每个进程/线程占用的处理器都在读写同一个变量serviceNum ，每次读写操作都必须在多个处理器缓存之间进行缓存同步，这会导致繁重的系统总线和内存的流量，大大降低系统整体的性能。 下面介绍的CLH锁和MCS锁都是为了解决这个问题的。 CLH锁CLH锁也是一种基于链表的可扩展、高性能、公平的自旋锁，申请线程只在本地变量上自旋，它不断轮询前驱的状态，如果发现前驱释放了锁就结束自旋。 import java.util.concurrent.atomic.AtomicReferenceFieldUpdater; public class CLHLock { public static class CLHNode { private volatile boolean isLocked = true; // 默认是在等待锁 } @SuppressWarnings(&quot;unused&quot; ) private volatile CLHNode tail ; private static final AtomicReferenceFieldUpdater&lt;CLHLock, CLHNode&gt; UPDATER = AtomicReferenceFieldUpdater .newUpdater(CLHLock.class, CLHNode.class , &quot;tail&quot; ); public void lock(CLHNode currentThread) { CLHNode preNode = UPDATER.getAndSet(this, currentThread); if(preNode != null) {//已有线程占用了锁，进入自旋 while(preNode.isLocked ) { } } } public void unlock(CLHNode currentThread) { // 如果队列里只有当前线程，则释放对当前线程的引用（for GC）。 if (!UPDATER.compareAndSet(this, currentThread, null)) { // 还有后续线程 currentThread.isLocked = false ;// 改变状态，让后续线程结束自旋 } } } 另一种实现 public class CLHLock { private static class QNode { volatile boolean locked; } private final AtomicReference&lt;QNode&gt; tail; private final ThreadLocal&lt;QNode&gt; myPred; private final ThreadLocal&lt;QNode&gt; myNode; public CLHLock() { // tail reference tail = new AtomicReference&lt;QNode&gt;(new QNode()); myNode = new ThreadLocal&lt;QNode&gt;() { protected QNode initialValue() { return new QNode(); } }; myPred = new ThreadLocal&lt;QNode&gt;(); } public void lock() { QNode node = myNode.get(); node.locked = true; QNode pred = tail.getAndSet(node); myPred.set(pred); while (pred.locked) { } } public void unlock() { QNode node = myNode.get(); node.locked = false; myNode.set(myPred.get()); } } MCS锁MCS Spinlock 是一种基于链表的可扩展、高性能、公平的自旋锁，申请线程只在本地变量上自旋，直接前驱负责通知其结束自旋，从而极大地减少了不必要的处理器缓存同步的次数，降低了总线和内存的开销。 import java.util.concurrent.atomic.AtomicReferenceFieldUpdater; public class MCSLock { public static class MCSNode { volatile MCSNode next; volatile boolean isBlock = true; // 默认是在等待锁 } volatile MCSNode queue;// 指向最后一个申请锁的MCSNode private static final AtomicReferenceFieldUpdater UPDATER = AtomicReferenceFieldUpdater .newUpdater(MCSLock.class, MCSNode.class, &quot;queue&quot;); public void lock(MCSNode currentThread) { MCSNode predecessor = UPDATER.getAndSet(this, currentThread);// step 1 if (predecessor != null) { predecessor.next = currentThread;// step 2 while (currentThread.isBlock) {// step 3 } }else { // 只有一个线程在使用锁，没有前驱来通知它，所以得自己标记自己为非阻塞 currentThread. isBlock = false; } } public void unlock(MCSNode currentThread) { if (currentThread.isBlock) {// 锁拥有者进行释放锁才有意义 return; } if (currentThread.next == null) {// 检查是否有人排在自己后面 if (UPDATER.compareAndSet(this, currentThread, null)) {// step 4 // compareAndSet返回true表示确实没有人排在自己后面 return; } else { // 突然有人排在自己后面了，可能还不知道是谁，下面是等待后续者 // 这里之所以要忙等是因为：step 1执行完后，step 2可能还没执行完 while (currentThread.next == null) { // step 5 } } } currentThread.next.isBlock = false; currentThread.next = null;// for GC } } CLH锁与MCS锁的比较 差异: 从代码实现来看，CLH比MCS要简单得多。 从自旋的条件来看，CLH是在前驱节点的属性上自旋，而MCS是在本地属性变量上自旋。 从链表队列来看，CLH的队列是隐式的，CLHNode并不实际持有下一个节点；MCS的队列是物理存在的。 CLH锁释放时只需要改变自己的属性，MCS锁释放则需要改变后继节点的属性。 注意：这里实现的锁都是独占的，且不能重入的。]]></content>
      <categories>
        <category>并发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[AQS]]></title>
    <url>%2F2017%2F01%2F17%2FAQS%2F</url>
    <content type="text"><![CDATA[锁分类 自旋锁：自旋锁是一种非阻塞锁，也就是说，如果某线程需要获取自旋锁，但该锁已经被其他线程占用时，该线程不会被挂起，而是在不断的消耗CPU的时间，不停的试图获取自旋锁。 互斥锁：互斥锁是阻塞锁，当某线程无法获取互斥量时，该线程会被直接挂起，该线程不再消耗CPU时间，当其他线程释放互斥锁后，操作系统会激活那个被挂起的线程，让其投入运行。 同步器定义 内部同步状态的管理(例如：表示一个锁的状态是获取还是释放) 同步状态的更新和检查操作，且至少有一个方法会导致调用线程在同步状态被获取时阻塞，以及在其他线程改变这个同步状态时解除线程的阻塞 同步器支持的操作 阻塞和非阻塞（例如tryLock）同步。 可选的超时设置，让调用者可以放弃等待 通过中断实现的任务取消，通常是分为两个版本，一个acquire可取消，而另一个不可以。 同步器的实现伪代码acquire操作阻塞调用的线程，直到或除非同步状态允许其继续执行 acquire操作实现while (没有获得执行许可) { if (当前线程没有加入等待队列) { 将当前线程入队 } 可能阻塞当前队列 } 如果当前线程在等待队列中，将其移除队列 release操作实现release操作是通过某种方式改变同步状态，使得一或多个被acquire阻塞的线程继续执行 更新同步状态 if (某一被阻塞线程被允许执行acquire操作) 激活一个或多个等待队列中的线程 实现的关键点 同步状态的原子性管理； 线程的阻塞与解除阻塞； 队列的管理； 同步状态AQS类使用单个int（32位）来保存同步状态，并暴露出getState、setState以及compareAndSet操作来读取和更新这个状态。这些方法都依赖于j.u.c.atomic包的支持，这个包提供了兼容JSR133中volatile在读和写上的语义，并且通过使用本地的compare-and-swap或load-linked/store-conditional指令来实现compareAndSetState，使得仅当同步状态拥有一个期望值的时候，才会被原子地设置成新值。 基于AQS的具体实现类必须根据暴露出的状态相关的方法定义tryAcquire和tryRelease方法，以控制acquire和release操作。当同步状态满足时，tryAcquire方法必须返回true，而当新的同步状态允许后续acquire时，tryRelease方法也必须返回true。这些方法都接受一个int类型的参数用于传递想要的状态。例如：可重入锁中，当某个线程从条件等待中返回，然后重新获取锁时，为了重新建立循环计数的场景。很多同步器并不需要这样一个参数，因此忽略它即可。 阻塞用LockSuport类解决阻塞问题，方法LockSupport.park阻塞当前线程除非/直到有个LockSupport.unpark方法被调用（unpark方法被提前调用也是可以的）。unpark的调用是没有被计数的，因此在一个park调用前多次调用unpark方法只会解除一个park操作。park方法同样支持可选的相对或绝对的超时设置，以及与JVM的Thread.interrupt结合 —— 可通过中断来unpark一个线程。 队列整个框架的关键就是如何管理被阻塞的线程的队列，该队列是严格的FIFO队列，因此，框架不支持基于优先级的同步。 CLH队列是一个链表队列，通过两个字段head和tail来存取，这两个字段是可原子更新的，两者在初始化时都指向了一个空节点。 一个新的节点，node，通过一个原子操作入队： do { pred = tail; } while(!tail.compareAndSet(pred, node)); 每一个节点的“释放”状态都保存在其前驱节点中。因此，自旋锁的“自旋”操作就如下： while (pred.status != RELEASED); // spin 自旋后的出队操作只需将head字段指向刚刚得到锁的节点： head = node; CLH锁的优点在于其入队和出队操作是快速、无锁的，以及无障碍的（即使在竞争下，某个线程总会赢得一次插入机会而能继续执行）；且探测是否有线程正在等待也很快（只要测试一下head是否与tail相等）；同时，“释放”状态是分散的（译者注：几乎每个节点都保存了这个状态，当前节点保存了其后驱节点的“释放”状态，因此它们是分散的，不是集中于一块的。），避免了一些不必要的内存竞争。 最终实现if(!tryAcquire(arg)) { node = new Node(); pred = node&apos;s effective predecessor; while (pred is not head node || !tryAcquire(arg)) { if (pred&apos;s signal bit is set) park() else compareAndSet pred&apos;s signal bit to true; pred = node&apos;s effective predecessor; } head = node; }]]></content>
  </entry>
  <entry>
    <title><![CDATA[网络层]]></title>
    <url>%2F2017%2F01%2F06%2F%E7%BD%91%E7%BB%9C%E5%B1%82%2F</url>
    <content type="text"><![CDATA[提供的服务 面向连接（虚电路）：虚电路是网络层向传输层提供的一种使所有分组按顺序到达目的端系统的可靠数据传送方式。进行数据交换的两个端系统之间存在着一条为它们服务的虚电路。 无连接：在需要经过很多个路由的通信线路上，数据报通过路由器自行选择走的线路。这样的通信是所谓的【尽最大努力交付】的不可靠传输。 现在的因特网都用的是【数据报服务】，因为现在的主机比较强大，信息传输的可靠性可以由主机来完成，在TCP/IP协议中，一般是TCP层来完成。 IP和IP协议配套的有3个协议： 地址解析协议ARP 网际控制报文协议ICMP 网际组管理协议IGMP 目的IP协议是用来转发数据的，用来告诉数据要发送到那个机器上。但是计算机在转发数据的时候，最终都是通过MAC地址转发完成的，知道源主机和目标主机的MAC地址，就可以把数据发送过去。那既然这样，为什么我们还要用IP协议？ 具体原因是这样的，生产适配器的厂商很多，然后就衍生出各种格式的MAC地址，MAC地址不统一，数据就发送不了！！！！！这时候，IP协议从天而降。把各种异构网络（不同的寻址方案，不同的超时控制，不同的路由选择技术……）互连起来，形成了一个【虚拟互连网络】。使用了IP协议后，网络层看起来就好像一个统一的网络。 分类 分类的IP地址 子网的划分 构成超网 分类的IP地址分类的IP地址是由两部分组成，即 IP地址::={&lt;网络号&gt;，&lt;主机号&gt;} 不知道是哪个国家的惯例，“：：=”的意思是“定义为”。咱就这样记吧，也比较好记。 IP地址是由ICANN这个机构给分配的，它只分配 网络号，所以一个网络号在因特网内必须唯一，而主机号在它前面的网络号中也是唯一的。可见IP地址在整个因特网范围内是唯一的。 第一个阶段，分类的IP地址共有5类地址 具体就是图上这样的，A类，B类，C类地址的网络号字段分别是1，2，3字节场，最前面的1~3位是类别位，数值规定分别是0， 10， 110 D类地址用于多播（一对多通信） E类地址作为保留为以后用。 IP地址都是32位的二进制代码，这样的代码对于计算机来说是方便了，但是对于我们来说就不好读了，所以，规定用 点分十进制记法 来表示IP，大家肯定都见过，比如说202.113.88.91这样的地址，其实就是11001010 1110001 1011000 1011011的点分十进制记法。 最常用的IP是A，B，C三类。下面给大家看一看各类IP的实际范围。 A类： 1.0.0.1-126.255.255.254（实际IP） 1.0.0.0-127.255.255.254（理论上的IP） 为什么会出现这种情况?下面再讲，先看完IP范围 B类： 128.0.0.1-191.255.255.254（实际IP） 128.0.0.0-191.255.255.254（理论IP） C类： 192.0.0.1-223.255.255.254（实际IP） 192.0.0.0-223.255.255.254（理论IP） IP地址中，全0主机号字段表示该IP地址是“本主机”所连接到的单个网络地址。比如1.0.1.1就表示网络地址为1.0.0.0 一般，全零（“0．0．0．0”）地址对应于当前主机。全“1”的IP地址（“255．255．255．255”）是当前子网的广播地址。 IP地址有四个特点： IP地址是分等级的地址结构。IP地址管理机构分配IP时，只分配网络号（第一级），主机号（第二级）由得到网络号的单位自行分配，并且，路由器仅根据目的主机的网络号来转发分组 IP地址是主机和链路的接口，若主机要练到两个网络，则需要两个IP，网络号必须不同，这种主机称为多归属主机。 具有同样网络号的主机的集合就称为一个网络。就是说，只要网络号相同，就是在同一个网络里。 所有网络号都是平等的 IP地址与硬件地址从网络层进到数据链路层的时候，IP数据报首部就被当做数据链路层的数据封装进去了！所以说，数据链路层是看不见数据报的IP地址的。在IP层中，源IP地址和目的IP地址始终不变。而数据链路层中的MAC地址一直在随着路由器的转发改变。这就是他们最大的区别了！但是这会引起另外一个问题，不知道大家注意没有，MAC地址一直在变，那主机或者路由器怎么知道MAC帧首部应该填入什么硬件地址？好。。。这就是下面要说的问题，也是重点：【地址解析协议ARP】 地址解析协议ARPARP的作用就是这个： IP地址→ARP协议→硬件地址 每个主机中都设有的一个【ARP高速缓存】，ARP高速缓存中包含 本局域网上的各主机和路由器的IP地址到硬件地址的映射表。就是通过这个表，IP地址就可以找到对应的硬件地址。 那最开始的时候是怎么生成这个表的呢？具体是这样 如果ARP高速缓存中没有目标IP对应的物理地址，主机就给局域网内所有的主机发送广播，然后对应IP的主机收到后，以单播的形式回答ARP请求。这时候，发送请求的主机A就把目的IP地址主机B的【IP与MAC地址的映射】写入到A自己的ARP高速缓存中。同时，B也得到了A的IP和MAC地址的对应，也将此映射写到B自己的ARP高速缓存中。 当然，既然叫 ARP高速缓存 了，那它就是一个缓存，既然是缓存就一定会在一定时间之后删除掉。 这个时间，就叫【生存时间】，每个映射项目都会设置一个生存时间。这种机制是保持网络通信的优良解决方案。 防止出现这种情况：就加入A的ARP高速缓存中有B的硬件地址的映射，但是B的适配器坏了，换了块新的。这时候，A就联系不上B了。因为A中存的B的硬件地址已经更改了。然后过了一小段时间，A的ARP高速缓存删除了B的原先的硬件地址，然后重新广播找到B的新硬件地址。 上面说的是在同一局域网的情况，如果要通信的两台主机不在同一局域网的话，就解析出要转发的路由器的MAC地址，把数据发给路由器，路由器通过路由表转发出去，最后通过最后一个路由再解析出要目标IP的MAC地址，传输数据！ 另外，这种解析都是自动进行的，对用户来说是透明的！用户完全不知道发生了些什么。 到了这里，我再提一提为什么要用IP地址！ARP是把IP地址转为MAC地址的协议，既然最后的传送都用的硬件地址，为什么还要使用IP地址多此一举的转化？就像我最开始说的，MAC地址的规格不统一~，所以，所以，用IP地址来统一所有的不同的异构网络，不同的MAC地址！ IP数据报的格式IP数据包你由两部分组成，首部和数据。首部又由两部分组成，分别是20字节的固定长度和固定部分后的可选字段 IP首部 版本： 指IP协议的版本，通信双方版本必须一致，现在一般用的IPv4，以后会用到IPv6 首部长度： 占4位，最长60字节，最小20字节，不要问为什么，，，，不要深究，当时我以深究就陷进去了，简单的这个地方纠结了好几天。 区分服务： 只有在区分服务的时候，这个字段才起作用。貌似这个字段现在没什么用。。。。。 总长度： 指首部和数据的总和，占16位，最长可达65535（二进制16个1），但IP在数据链路层规定了数据帧中 数据字段的最大长度，一般称为【最大传送单元MTU】 标识： 具有相同标识的数据报片段最后能正确的组装在一起。标识是这样生成的 → IP软件中有个计数器，一旦生成数据报，计数器就+1并且将值赋给标识字段。数据报太长而要分片时，这个值就被赋给所有标识字段。 标志： 有3位，只有两位有意义。 最低位（最后一位）是MF， MF=1 表示后面“还有分片” MF=0表示这是若干个数据报片中的最后一个。中间位是DF，意思是“不能分片”。 DF=0才允许分片 片偏移： 较长分组分片后，某片在原分组中的位置。即 相对于用户数据报字段的起点，该片从何处开始。片偏移以8个字节为偏移单位。（后面给大家一个书上的例子讲解一下） 生存时间： 表明数据报在网络中的寿命，现在以“跳数”为单位，没跳过一个路由器跳数-1，跳数为0则数据部被丢弃 协议： 指出该数据报携带的数据是使用何种协议 首部检验和： 这个字段只检验数据部首部，不包括数据部分。 IP层转发分组的流程IP层转发分组的规则其实很简单， 分组从一个路由转发到另一个路由，最后一个路由向目的主机交付 什么是最后一个路由？就是你分组转发的某个路由，而路由连接到分组要去的网络，然后这个路由就直接把分组交付了路由表里的信息很简单，主要就是（目的网络地址，下一跳地址） 这样，路由器根据分组的IP地址查找对应的目的网络地址，得出下一跳地址（目的地址对应的下一跳地址是根据路由选择协议自行计算出来的）。 还有特定主机路由，特定主机路由即指某一台主机直接指定一个路由，我的分组就从这个路由转发出去 还有默认路由，对IP数据包中的目的地址找不到存在的其他路由时，路由器所选择的路由。 划分子网划分子网的原因就是，IP地址不够用了，现在的分配方式比较浪费IP地址。所以，现在就“划分子网”了。 思路： 划分子网是一个单位的网络内部的事情（比如一个大学内部），整个大学的网络对外人任然表现为一个网络 从主机号，借若干位作为子网号（借用以后，主机号就少了，借多少就少多少）。然后二级IP就变成了三级IP，IP地址：：= {&lt;网络号&gt;，&lt;子网号&gt;，&lt;主机号&gt;} 发送分组的时候任然和以前一样，就是最后的一个路由（即到了本单位网络上的路由），通过目的地址和子网掩码得到 子网号，然后发送分组~~ 子网中最重要的东西子网掩码，子网掩码的作用就是为了让本单位中的路由器找到所划分的子网。如果没有划分子网，默认的子网掩码就是下面这样 A类地址的默认子网掩码是255.0.0.0，换算成二进制，就是11111111 00000000 00000000 00000000 B类地址的默认子网掩码是255.255.0.0，换算成二进制，就是11111111 11111111 00000000 00000000 C类地址的默认子网掩码是255.255.255.0，换算成二进制，就是11111111 11111111 11111111 00000000 如果是划分了呢？那就是这样的，比如现在划分A类的子网 子网号的位数2位（即借用主机号2位） 11111111 11000000 00000000 00000000（二进制就是这样的） 换成10进制255.192.0.0（子网掩码） 子网号的位数3位（即借用主机号3位） 11111111 11100000 00000000 00000000（二进制就是这样的） 换成10进制255.224.0.0（子网掩码） 子网数和每个子网中主机数的确认是这样的举例：假如子网号有两位，则可能的子网数共为2²，但是全0和全1不可用，所以子网数为2²-2=2，主机数2^22-2 那通过子网掩码和IP地址如何计算出网络地址呢？很简单啊，做个简单的与运算……举例：IP地址为141.14.72.24 子网掩码为255.255.192.0 网络地址就这样求目的地址（十进制）：10001101 00001110 01001000 00011000子网掩码（十进制）：11111111 11111111 11000000 00000000进行与运算，最后得到：10001101 00001110 01000000 00000000，换算成10进制就是141.14.64.0（这个就是网络地址了~）]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据链路层]]></title>
    <url>%2F2017%2F01%2F05%2F%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%B1%82%2F</url>
    <content type="text"><![CDATA[From：http://blog.csdn.net/zeroblack/article/details/12851607 数据链路层什么是数据链路层？答：数据链路层是计算机网络的中的低层（OSI模型中的第二层），可简单的理解为是数据通道。主要作用是为上层（网络层）提供带有差错检测的不可靠传输服务。 数据链路和链路有什么区别？答：链路是从一个结点到相邻结点的一段物理线路，而中间没有其他的交换结点。说白了，链路就相当于传输数据的载体。 计算机网络中共分几层（计算机网络的体系结构）？答：计算机网络主要有OSI模型（七层）和TCP/IP模型（四层），当然，现在OSI已经不用了，我们就讲一下TCP/IP模型。为了学习研究方便， 我们把TCP/IP模型分为五层，从上至下分别是【应用层】【运输层】【网络层】【数据链路层】【物理层】 数据链路层要解决的问题有哪些？数据链路层总共要解决三个大问题：封装成帧、透明传输、差错检测 封装成帧：即把上层网络层传下来的数据分别添加首部和尾部，这样就构成了一个帧。【帧首部】和【帧尾部】重要作用是判断帧从哪开始发送，从哪结束，一般用一些特殊的字符代表。 透明传输：什么叫透明传输？就是，不管你传什么数据，链路层都能给你传。实际存在的数据链路层对数据来说好像不存在一样。这就是透明传输。那为了让所有的数据都能通过数据链路层传输，我们该做什么呢？帧的数据部分都是要传输的内容，帧首部和帧尾部用来告诉接收方帧是否传完。那如果数据部分恰好含有帧的首部或者尾部怎么办？假设数据部分含有帧尾部的特殊字符，接收方就会认为这个帧传输结束了。这样就做不到透明传输了。解决办法：转义字符。 差错检测：传输过程中，可能会发生0变1,1变0的情况，差错检测就是为了避免这种情况，检测到有问题的比特流，直接丢弃。差错检测的方法叫做 循环冗余检测CRC，本质就是用传输的二进制码除以一个发送方和接收方商议好的二进制数，然后双方检验。 广播信道定义广播信道是一对多的通信，在局域网中使用的最广。那什么是局域网？网络为一个单位所拥有，且地理范围和站点数据均有限。 局域网有3个有点：（1）有广播功能，从一个机器可以访问到整个网络 （2）方便扩展，设备的位置灵活可变 （3）提高了系统的可靠性、可用性、生存性。 局域网按照网络拓扑方式分的话分为3中：（1）星形网 （2）总线网 （3）环形网 现在，网络发达了，大规模集成电路的质量上去了，所以用的最多的是星形网，星形网用一个集线器来接收信息并广播到所有的结点上。 以太网以太网就是现在用的最广泛的局域网，共有两个标准。第一个是 DIX Ethernet V2，另一个是IEEE 802.3。 IEEE 802.3把局域网的链路层拆为两个子层，（1）逻辑链路控制LLC （2）媒体接入控制MAC。 由于各种原因，LLC已经基本不用了。所以我们着重介绍MAC 讲MAC之前，我们需要先了解一下 适配器，适配器又叫网卡。网卡最大的功能是缓冲数据再发送，避免了网络数据率和总线数据率不同而可能引起的问题。每个适配器里都有一个独一无二的，固定的物理地址，这个物理地址就是我们所说的MAC地址。所谓广播就是集线器给局域网内的各个站点发送出此数据帧后，只有适配器的MAC地址与数据帧中的目的地址匹配的那个站才接收数据，其他的站就丢掉帧。 以太网采用的协议CSMA/CD协议。 CSMA/CD的意思的载波监听多点接入/碰撞检测 （这里的载波不是指那种传输数据的载波，只是借用一个这个词） 多点接入：就是说网络是总线型的（星形网也是总线型的一种）。CSMA/CD是双向交替通信（半双工通信） 载波监听：不管发送前，还是发送中，每个站必须不停的检测信道。 发送前检测，是为了获得发送权，如果检测出信道中有数据，就不能发送。发送中检测，是为了及时发现有没有和其他的数据碰撞，也就是下面要说的碰撞检测 碰撞检测：当两个或以上的站发传送的数据同时在总线上时，总线上的电压变化幅度就会变大，容易造成传输中的数据损坏。 以太网扩展 物理层扩展 数据链路层扩展 网桥就是这样的，把每个以太网称为一个【网段】，网桥就是用来连接各个网段的。网桥依靠转发表来转发帧，转发表是通过网桥的【自学习】得到的。自学习就是每个经过网桥发送的站都经过记录（记录源地址和进入网桥的端口） 网桥有几个优点： 过滤通信量，增大吞吐量 扩大了物理范围 提高了可靠性 可互连不同物理层，不同MAC子层和不同速率的以太网 第二种扩展方式是【交换机】 多接口的网桥——以太网交换机 交换机和集线器区别在哪？ 集线器特点：这种局域网在逻辑上仍然是一个总线网，局域网上的各主机共享逻辑上的总线，使用的还是CSMA/CD协议（别忘了CSMA/CD协议是半双工方式工作的）。网络中各主机必须竞争传输媒体的控制，同一时刻至多只允许一个主机发送数据 交换机特点：交换机的每个接口都直接与一个主机或另一个集线器相连，并且一般以全双工方式工作。用以太网交换机的话就可以把各种速率的以太网就都连到一起。并且以太网交换机可以轻松的实现【虚拟局域网VLAN】 ○交换机的本质类似于分区表，将广播时将全网广播变更为向某一部分网络广播，降低了碰撞概率，提高了信息传递效率。 From：知乎 交换机工作于数据链路层，用来隔离冲突域，连接的所有设备同属于一个广播域（子网），负责子网内部通信。 路由器工作于网络层，用来隔离广播域（子网），连接的设备分属不同子网，工作范围是多个子网之间，负责网络与网络之间通信。 举个例子：家用宽带路由器，其实是交换机和路由器的结合体，有两个网络层接口，一个连接运营商网络，物理上也就是wan口，IP地址由运营商分配。另一个连接家庭网络，没有物理接口，IP地址由自己通过路由器管理界面配置，一般默认是192.168.1.1那另外几个Lan口干什么用的？这就是交换机接口，和家庭网络接口相连，负责家庭网络内部通信。]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>网络</tag>
        <tag>IP</tag>
        <tag>TCP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Operating Systems读书笔记(Virtualization)]]></title>
    <url>%2F2016%2F08%2F13%2FOperating-Systems%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[《Operating Systems:Three Easy Pieces》 操作系统的核心问题 HOW DOES THE OPERATING SYSTEM VIRTUALIZE RESOURCES? 虚拟化CPU支持多任务同时执行 虚拟化内存提供无限大的内存空间，进程内存互相不影响 HOW TO BUILD CORRECT CONCURRENT PROGRAMS? HOW TO STORE DATA PERSISITENTLY? CPU虚拟化进程 HOW TO PROVIDE THE ILLUSION OF MANY CPUS? 进程的上下文： 内存，指令与数据 寄存器 PC,Stack Pointer，Frame Pointer I/O 堆，栈 在unix系统中，每个进程都会默认有3个文件描述符，标准输入，输出，错误 main方法？ 进程的状态： 运行 准备 阻塞，A common example: when a process initiates an I/O request to a disk, it becomes blocked and thus some other process can use the processor. 进程状态转换图 进程数据结构 虚拟化CPU的挑战 HOW TO EFFICIENTLY VIRTUALIZE THE CPU WITH CONTROL? 限制性行为 用户模式 内核模式 操作系统在启动的时候注册系统调用表，操作系统会通知硬件当发生系统调用时应该去执行什么代码。 进程切换 HOW TO REGAIN CONTROL OF THE CPU HOW TO GAIN CONTROL WITHOUT COOPERATION 利用timer interrupt，操作系统可以在任何情况下获得控制权。这个时间设备可被编程实现为每n毫秒进行一次中断，当中断发生时，当前正在运行的进程会停止，而一个之前被设置好的OS handler会开始执行，这样操作系统就获得了CPU的控制权，然后就可以停止当前进程，并开始另一个进程。 流程 保存上下文 进程调度策略 HOW TO DEVELOP SCHEDULING POLICY 评价标准The turnaround time of a job is definedas the time at which the job completes minus the time at which the jobarrived in the system Tturnaround=Tcompletion-Tarrival Response time is defined as the time from when the job arrives in asystem to the first time it is scheduled Tresponse=Tfirstturn-Tarrival 具体策略 FIFO（延时太大，公平） Shortest Job First（响应时间） Shortest Time-to-Completion First（响应时间） Round Robin（实时） The Multi-Level Feedback Queue HOW TO SCHEDULE WITHOUT PERFECT KNOWLEDGE? 基本规则 Rule 1: If Priority(A) &gt; Priority(B), A runs (B doesn’t). Rule 2: If Priority(A) = Priority(B), A &amp; B run in RR. Rule 3: When a job enters the system, it is placed at the highest priority (the topmost queue). Rule 4: Once a job uses up its time allotment at a given level (regardless of how many times it has given up the CPU), its priority is reduced (i.e., it moves down one queue). Rule 5: After some time period S, move all the jobs in the system to the topmost queue. Lottery Scheduling HOW TO SHARE THE CPU PROPORTIONALLY 完全准确的按照权重调度，比如A:B:C=100:50:250，用一个大整数比如10000除以它们，分别是100，200和40，每run一次加100，200和40 current = remove_min(queue); // pick client with minimum pass schedule(current); // use resource for quantum current-&gt;pass += current-&gt;stride; // compute next pass using stride insert(queue, current); // put back into the queue Multiprocessor Scheduling HOW TO SCHEDULE JOBS ON MULTIPLE CPUS 内存虚拟化 HOW TO VIRTUALIZE MEMORYHOW TO EFFICIENTLY AND FLEXIBLY VIRTUALIZE MEMORY 为每个进程创造出一个从地址0开始，几乎无限大的内存空间。所以，需要翻译地址，虚拟地址-&gt;物理地址，还有之后的虚拟内存。 地址空间 堆和栈的扩张方向正好相反，堆从小到大，栈从大到小JVM地址空间？ 地址翻译 base，基地址 bound(limit)，边界，防止地址越界 physical address = virtual address + base 空间分配操作系统需要维护空闲内存列表，当进程创建的时候，找到空闲的内存块分配给它。当进程销毁的时候，从进程回收内存，放入空闲内存列表。 操作系统与硬件的交互 内存分段整个进程没必要物理上在一起，代码段，堆和栈可以物理隔离，这样可以保持灵活性，同时降低对大块内存的要求。如何知道是哪个段？通过在虚拟地址中加两位来解决。 栈需要指明扩展的方向，再加一位。 保护位再加一位 内存碎片问题 HOW TO MANAGE FREE SPACE FreeList策略 Best Fit Worst Fit First Fit Next Fit 分页 HOW TO VIRTUALIZE MEMORY WITH PAGES 分段可以给每一个进程分配不同的线性地址空间，而分页可以把同一线性地址空间映射到不同的物理空间 固定大小使得空闲空间管理变得简单，分页和分段的区别在于：分页会造成页内空间浪费，分段会造成段外空间碎片化，相对而言，分页的问题更好解决。 分页地址翻译 HOW TO SPEED UP ADDRESS TRANSLATION TLB HOW TO MANAGE TLB CONTENTS ON A CONTEXT SWITCH HOW TO DESIGN TLB REPLACEMENT POLICY LRU HOW TO MAKE PAGE TABLES SMALLER? 交换分区Present Bit代表是否交换 操作系统会维护high watermark (HW)和low watermark (LW)，当内存低于LW，会启动后台线程swap daemon or page daemon进行内存页清理，直到达到HW。]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>Operating Systems</tag>
      </tags>
  </entry>
</search>
